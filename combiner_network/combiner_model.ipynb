{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "combiner_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aVYRvdDcYxdR",
        "amhMvpjqYbtD",
        "aJFzDyDP0YOb"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNxQ86BlvNws+AmtwT+zoVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phil-Schwarz/TQA/blob/squbr%2Fcombiner_network/combiner_network/combiner_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSL6cLR30di5"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVGyIEpKe0yP",
        "outputId": "4be486c7-a76f-4cb4-84c3-c11aed49cf7c"
      },
      "source": [
        "!pip install jsonlines"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/58/06f430ff7607a2929f80f07bfd820acbc508a4e977542fefcc522cde9dff/jsonlines-2.0.0-py3-none-any.whl\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx7p9UEDchcq"
      },
      "source": [
        "from keras.layers import Dense, Input, TimeDistributed, LSTM\n",
        "from keras.layers import Concatenate, Dropout, SpatialDropout1D\n",
        "from keras.models import Model\n",
        "import argparse\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "#import arch, utils\n",
        "#from settings import TRAIN_DATA_PATH, VAL_DATA_PATH\n",
        "#from settings import MODELS_DIR, TOP_N\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Kv_attention\n",
        "#import tensorflow as tf\n",
        "#from keras import backend as K\n",
        "#from keras.engine import Layer\n",
        "\n",
        "#import torch\n",
        "#import torch.nn as nn\n",
        "#import torchvision\n",
        "#import torchvision.transforms as transforms\n",
        "\n",
        "import jsonlines\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROlFpVIzDYYh"
      },
      "source": [
        "## CONSTANTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRhCnUAEDXJr"
      },
      "source": [
        "# TRAIN_DATA_PATH =\n",
        "# VAL_DATA_PATH = \n",
        "DOC_QUANTITY = 2\n",
        "NUM_SCORES = 3\n",
        "#LEN_DATASET = 4000\n",
        "TOP_N = 20\n",
        "MODELS_DIR = \"content/model\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAJ6WpSkySEa"
      },
      "source": [
        "## Generate Random Input Data to train Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6g-RiKHyX2g"
      },
      "source": [
        "#utils.py\n",
        "\n",
        "# Returns a dictionary of entries (for answers) and their labels. To be\n",
        "# directly wired into Keras methods (fit, predict, etc.).\n",
        "# Does not shuffle the questions.\n",
        "class utils:\n",
        "\n",
        "  # Returns a list of entries. To be fed into @to_numpy to extract tensors\n",
        "  # that can be directly wired to Keras @fit.\n",
        "  def read_dataset(file_path, top_n, mask_IR=False,\n",
        "                mask_Ranking=False, mask_answer_verifier=False):\n",
        "    # assert(isinstance(top_n, int))\n",
        "    # assert(top_n >= 1)\n",
        "\n",
        "    data = None\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    # assert(data is not None)\n",
        "    # assert(len(data) == 1)\n",
        "    # assert(\"data\" in data)\n",
        "\n",
        "    def chunks(array, n):\n",
        "        \"\"\"Yield successive n-sized chunks from array.\"\"\"\n",
        "        for i in range(0, len(array), n):\n",
        "            yield array[i:i + n]\n",
        "\n",
        "    def keep_top_n(array):\n",
        "        # assert(isinstance(array, list))\n",
        "        # assert(len(array) >= top_n * NUM_SOURCES)\n",
        "        # assert(len(array) % NUM_SOURCES == 0)\n",
        "        chunk_size = len(array) // NUM_SOURCES\n",
        "        array = list(chunks(array, chunk_size))\n",
        "        # assert(len(array) == NUM_SOURCES)\n",
        "        # for chunk_id in range(0, NUM_SOURCES):\n",
        "            # array[chunk_id] = array[chunk_id][:top_n]\n",
        "        processed_array = []\n",
        "        for chunk_id in range(0, NUM_SOURCES):\n",
        "            # assert(len(array[chunk_id]) == top_n)\n",
        "            processed_array += array[chunk_id]\n",
        "        # assert(len(processed_array) == top_n * NUM_SOURCES)\n",
        "        return processed_array\n",
        "\n",
        "    data = data[\"data\"]\n",
        "    assert(isinstance(data, list))\n",
        "    for entry in data:\n",
        "        # assert(len(entry) == 6)\n",
        "        # assert(\"question_id\" in entry)\n",
        "        # assert(\"answers\" in entry)\n",
        "        # assert(\"correct_answer\" in entry)\n",
        "        # assert(\"question_text\" in entry)\n",
        "        # assert(\"answers_text\" in entry)\n",
        "        # assert(\"documents\" in entry)\n",
        "        # assert(entry[\"correct_answer\"] in [0, 1, 2, 3])\n",
        "        # assert(isinstance(entry[\"answers\"], list))\n",
        "        # assert(len(entry[\"answers\"]) == 4)\n",
        "        # assert(isinstance(entry[\"documents\"], list))\n",
        "        # assert(len(entry[\"documents\"]) == 4)\n",
        "        # assert(isinstance(entry[\"question_text\"], str))\n",
        "        # assert(len(entry[\"answers_text\"]) == 4)\n",
        "        # for answer_text in entry[\"answers_text\"]:\n",
        "        #     assert(isinstance(answer_text, str))\n",
        "\n",
        "        # Keep only TOP_N entries from each source.\n",
        "        for idx in [0, 1, 2, 3]:\n",
        "            entry[\"answers\"][idx] = keep_top_n(entry[\"answers\"][idx])\n",
        "            # assert(len(entry[\"answers\"][idx]) == top_n * NUM_SOURCES)\n",
        "            entry[\"documents\"][idx] = keep_top_n(entry[\"documents\"][idx])\n",
        "            # assert(len(entry[\"documents\"][idx]) == top_n * NUM_SOURCES)\n",
        "\n",
        "        for answer in entry[\"answers\"]:\n",
        "            # assert(isinstance(answer, list))\n",
        "            # assert(len(answer) == top_n * NUM_SOURCES)\n",
        "            for local_answer in answer:\n",
        "                # assert(isinstance(local_answer, list))\n",
        "                # assert(len(local_answer) == NUM_FEATURES)\n",
        "                if mask_IR:\n",
        "                    local_answer[1] = 0.0\n",
        "                if mask_Ranking:\n",
        "                    local_answer[2] = 0.0\n",
        "                if mask_answer_verifier:\n",
        "                    local_answer[3] = 0.0\n",
        "            # assert([x[0] for x in answer] == NUM_SOURCES * list(range(1, top_n + 1)))  # noqa: E501\n",
        "    return data\n",
        "\n",
        "\n",
        "  # Augment the dataset with all answer permutations such that the neural\n",
        "  # network cannot learn how to decide based on positions.\n",
        "  # Returns the newly constructed dataset.\n",
        "  def augment_with_permutations(dataset):\n",
        "    assert(isinstance(dataset, list))\n",
        "    augmented = []\n",
        "    for entry in dataset:\n",
        "      # assert(len(entry) == 6)\n",
        "      # assert(\"question_id\" in entry)\n",
        "      # assert(\"answers\" in entry)\n",
        "      # assert(\"correct_answer\" in entry)\n",
        "      # assert(\"question_text\" in entry)\n",
        "      # assert(\"answers_text\" in entry)\n",
        "      # assert(\"documents\" in entry)\n",
        "      for answer_text in entry[\"answers_text\"]:\n",
        "          assert(isinstance(answer_text, str))\n",
        "\n",
        "      correct_answer = entry[\"correct_answer\"]\n",
        "      answers = entry[\"answers\"]\n",
        "      documents = entry[\"documents\"]\n",
        "      answers_text = entry[\"answers_text\"]\n",
        "      # assert(correct_answer in [0, 1, 2, 3])\n",
        "      # assert(isinstance(answers, list) and len(answers) == 4)\n",
        "      # assert(isinstance(documents, list) and len(documents) == 4)\n",
        "      for perm in itertools.permutations([0, 1, 2, 3]):\n",
        "        permuted_answers = [answers[i] for i in perm]\n",
        "        permuted_answers_text = [answers_text[i] for i in perm]\n",
        "        permuted_documents = [documents[i] for i in perm]\n",
        "        permuted_correct_answer = perm.index(correct_answer)\n",
        "        # assert(permuted_correct_answer in [0, 1, 2, 3])\n",
        "        augmented.append({\n",
        "                \"question_id\": entry[\"question_id\"],\n",
        "                \"correct_answer\": permuted_correct_answer,\n",
        "                \"answers\": permuted_answers,\n",
        "                \"question_text\": entry[\"question_text\"],\n",
        "                \"documents\": permuted_documents,\n",
        "                \"answers_text\": permuted_answers_text\n",
        "        })\n",
        "    # assert(len(augmented) == 24 * len(dataset))\n",
        "    # for entry in augmented:\n",
        "    #     assert(len(entry) == 6)\n",
        "    #     assert(\"question_id\" in entry)\n",
        "    #     assert(\"answers\" in entry)\n",
        "    #     assert(\"correct_answer\" in entry)\n",
        "    #     assert(\"question_text\" in entry)\n",
        "    #     assert(\"answers_text\" in entry)\n",
        "    #     assert(\"documents\" in entry)\n",
        "    #     for answer_text in entry[\"answers_text\"]:\n",
        "    #         assert(isinstance(answer_text, str))\n",
        "    return augmented\n",
        "\n",
        "  def to_numpy(dataset, top_n):\n",
        "    assert(isinstance(dataset, list))\n",
        "    assert(isinstance(top_n, int))\n",
        "    assert(top_n >= 1)\n",
        "\n",
        "    answer_a = np.zeros((len(dataset), NUM_DSOURCES * top_n, NUM_FEATURES),\n",
        "                        dtype=\"float\")\n",
        "    answer_b = np.zeros((len(dataset), NUM_SOURCES * top_n, NUM_FEATURES),\n",
        "                        dtype=\"float\")\n",
        "    answer_c = np.zeros((len(dataset), NUM_SOURCES * top_n, NUM_FEATURES),\n",
        "                        dtype=\"float\")\n",
        "    answer_d = np.zeros((len(dataset), NUM_SOURCES * top_n, NUM_FEATURES),\n",
        "                        dtype=\"float\")\n",
        "    labels = np.zeros((len(dataset), 4), dtype=\"int32\")\n",
        "\n",
        "    def process_answer(answer):\n",
        "      # assert(isinstance(answer, list))\n",
        "      answer = np.array(answer, dtype=\"float\")\n",
        "      # assert(answer.shape == (NUM_SOURCES * top_n, NUM_FEATURES))\n",
        "      answer[:, 0] *= (1.0 / top_n)\n",
        "      return answer\n",
        "\n",
        "    for (idx, entry) in enumerate(dataset):\n",
        "      answers = entry[\"answers\"]\n",
        "      correct_answer = entry[\"correct_answer\"]\n",
        "\n",
        "      answer_a[idx] = process_answer(answers[0])\n",
        "      answer_b[idx] = process_answer(answers[1])\n",
        "      answer_c[idx] = process_answer(answers[2])\n",
        "      answer_d[idx] = process_answer(answers[3])\n",
        "\n",
        "      labels[idx][correct_answer] = 1\n",
        "\n",
        "    # assert(isinstance(answer_a, np.ndarray))\n",
        "    # assert(isinstance(answer_b, np.ndarray))\n",
        "    # assert(isinstance(answer_c, np.ndarray))\n",
        "    # assert(isinstance(answer_d, np.ndarray))\n",
        "    # assert(isinstance(labels, np.ndarray))\n",
        "    return {\n",
        "            \"answer_a\": answer_a,\n",
        "            \"answer_b\": answer_b,\n",
        "            \"answer_c\": answer_c,\n",
        "            \"answer_d\": answer_d\n",
        "    }, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnfJnk4JlSLE",
        "outputId": "4252689d-f490-4305-ab73-7e6b33ee2742"
      },
      "source": [
        "# generating random test data\n",
        "def create_random_traindata(LEN_DATASET):\n",
        "  answer_a = np.zeros((LEN_DATASET, DOC_QUANTITY , NUM_SCORES),\n",
        "                      dtype=\"float\")\n",
        "  answer_b = np.zeros((LEN_DATASET, DOC_QUANTITY , NUM_SCORES),\n",
        "                      dtype=\"float\")\n",
        "  answer_c = np.zeros((LEN_DATASET, DOC_QUANTITY , NUM_SCORES),\n",
        "                      dtype=\"float\")\n",
        "  answer_d = np.zeros((LEN_DATASET, DOC_QUANTITY , NUM_SCORES),\n",
        "                      dtype=\"float\")\n",
        "  labels = np.zeros((LEN_DATASET, 2,4), dtype=\"int32\")\n",
        "\n",
        "  for i in range(0,LEN_DATASET):\n",
        "    rs1 = random.uniform(-1,1)\n",
        "    rs2 = random.uniform(-1,1)\n",
        "    ms1 = random.uniform(-1,1)\n",
        "    ms2 = random.uniform(-1,1)\n",
        "    answer_a[i][0] = np.array((rs1,ms1,ms2))\n",
        "    answer_a[i][1] = np.array((rs2,ms1,ms2))\n",
        "\n",
        "    rs1 = random.uniform(-1,1)\n",
        "    rs2 = random.uniform(-1,1)\n",
        "    ms1 = random.uniform(-1,1)\n",
        "    ms2 = random.uniform(-1,1)\n",
        "    answer_b[i][0] = np.array((rs1,ms1,ms2))\n",
        "    answer_b[i][1] = np.array((rs2,ms1,ms2))\n",
        "\n",
        "    rs1 = random.uniform(-1,1)\n",
        "    rs2 = random.uniform(-1,1)\n",
        "    ms1 = random.uniform(-1,1)\n",
        "    ms2 = random.uniform(-1,1)\n",
        "    answer_c[i][0] = np.array((rs1,ms1,ms2))\n",
        "    answer_c[i][1] = np.array((rs2,ms1,ms2))\n",
        "\n",
        "    rs1 = random.uniform(-1,1)\n",
        "    rs2 = random.uniform(-1,1)\n",
        "    ms1 = random.uniform(-1,1)\n",
        "    ms2 = random.uniform(-1,1)\n",
        "    answer_d[i][0] = np.array((rs1,ms1,ms2))\n",
        "    answer_d[i][1] = np.array((rs2,ms1,ms2))\n",
        "\n",
        "    labels[i] = np.zeros(4, dtype=\"int32\")\n",
        "    index = random.randint(0, 3)\n",
        "    labels[i][0][index] = 1\n",
        "    labels[i][1][index] = 1\n",
        "  return {\n",
        "          \"answer_a\": answer_a,\n",
        "          \"answer_b\": answer_b,\n",
        "          \"answer_c\": answer_c,\n",
        "          \"answer_d\": answer_d\n",
        "  }, labels\n",
        "#create_random_traindata(4000)\n",
        "answer_a.shape\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVYRvdDcYxdR"
      },
      "source": [
        "## Get and prepare Dataset for Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb0-MGMgYw90"
      },
      "source": [
        "##  Get ARC Dataset from my GoogleDrive\n",
        "!gdown --id 1Fp5TIgoqJLg0uL69WSWlaztN7EclxwJl \n",
        "\n",
        "#Unzip\n",
        "!jar xvf ARC-V1-Feb2018.zip\n",
        "\n",
        "path_easy = \"ARC-V1-Feb2018-2/ARC-Easy/ARC-Easy-Train.jsonl\"\n",
        "path_chall = \"ARC-V1-Feb2018-2/ARC-Challenge/ARC-Challenge-Train.jsonl\"\n",
        "\n",
        "def extract_questions_and_answers(path):\n",
        "  data_rows = []\n",
        "  answer_choices = []\n",
        "\n",
        "  with jsonlines.open(path) as reader:\n",
        "    for obj in reader:\n",
        "      id = obj[\"id\"]\n",
        "      question = obj[\"question\"][\"stem\"]\n",
        "      answer_key = obj[\"answerKey\"]# more possible answers\n",
        "      for answer_choice in obj[\"question\"][\"choices\"]:\n",
        "        answer_choices.append(answer_choice[\"label\"]+\": \"+answer_choice[\"text\"])\n",
        "\n",
        "      data_rows.append({\n",
        "            \"id\":id,\n",
        "            \"question\":question,\n",
        "            \"answer_choices\":answer_choices,\n",
        "            \"answer_key\":answer_key\n",
        "      })\n",
        "  return pd.DataFrame(data_rows)\n",
        "\n",
        "extract_questions_and_answers(path_easy)\n",
        "\n",
        "# # MNIST dataset \n",
        "# train_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "#                                            train=True, \n",
        "#                                            transform=transforms.ToTensor(),  \n",
        "#                                            download=True)\n",
        "\n",
        "# test_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "#                                           train=False, \n",
        "#                                           transform=transforms.ToTensor())\n",
        "\n",
        "# # Data loader\n",
        "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "#                                            batch_size=batch_size, \n",
        "#                                            shuffle=True)\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "#                                           batch_size=batch_size, \n",
        "#                                           shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amhMvpjqYbtD"
      },
      "source": [
        "## LSTM Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcMJmilZYefu"
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters \n",
        "# input_size = 784 # 28x28\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "input_size = 3 # one row at a time (tf-idf, destilbert, albert)                 #28\n",
        "sequence_length = 20 # amount of documents                                      #28\n",
        "hidden_size = 128\n",
        "num_layers = 2 # amount of rnn/lstm boxes\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        # -> x needs to be: (batch_size, seq, input_size)                         #what is batchsize -Batch size is a term used in machine learning\n",
        "                                                                                  # and refers to the number of training examples utilized in one iteration. \n",
        "        \n",
        "        # or:\n",
        "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Set initial hidden states (and cell states for LSTM)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
        "        \n",
        "        # x: (n, 28, 28), h0: (2, n, 128)\n",
        "        \n",
        "        # Forward propagate RNN\n",
        "        #out, _ = self.rnn(x, h0)  \n",
        "        # or:\n",
        "        out, _ = self.lstm(x, (h0,c0))                                            # underscore because we dont need this\n",
        "        \n",
        "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        # out: (n, 28, 128)\n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        out = out[:, -1, :]\n",
        "        # out: (n, 128)\n",
        "         \n",
        "        out = self.fc(out)                                                        # fully connected\n",
        "        # out: (n, 10)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJFzDyDP0YOb"
      },
      "source": [
        "## KVAttention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXnS0gZj55zK"
      },
      "source": [
        "# first we will implement a lstm and later on (if we have time) we will try to include kv-attention\n",
        "\n",
        "# this class is used as a layer in the model\n",
        "# this will be skipped at first\n",
        "# from kv_attention.py\n",
        "class KVAttention(Layer):\n",
        "\n",
        "    # attention_size is the variable k from the paper.\n",
        "    def __init__(self, key_size, value_size,\n",
        "                 return_attention_scores=False, **kwargs):\n",
        "        if K.backend() != 'tensorflow':\n",
        "            raise RuntimeError('KVAttention is only available with '\n",
        "                               'the TensorFlow backend.')\n",
        "        assert(isinstance(key_size, int) and key_size >= 1)\n",
        "        assert(isinstance(value_size, int) and value_size >= 1)\n",
        "        assert(isinstance(return_attention_scores, bool))\n",
        "\n",
        "        self.key_size = key_size\n",
        "        self.value_size = value_size\n",
        "        self.return_attention_scores = return_attention_scores\n",
        "        self.imput_dim = None\n",
        "        self.timestamps = None\n",
        "\n",
        "        super(KVAttention, self).__init__(**kwargs)\n",
        "\n",
        "    # The model receives an input with shape (batch_size, timestamp, input_dim)\n",
        "    def build(self, input_shape):\n",
        "        assert(len(input_shape) == 3)\n",
        "\n",
        "        self.timestamps = input_shape[1]\n",
        "        self.input_dim = input_shape[2]\n",
        "\n",
        "        self.key_embed_w = self.add_weight(\n",
        "                        shape=(self.input_dim, self.key_size),\n",
        "                        name='key_embed_w',\n",
        "                        initializer='glorot_uniform',\n",
        "                        trainable=True\n",
        "        )\n",
        "        self.key_embed_b = self.add_weight(\n",
        "                        shape=(self.key_size,),\n",
        "                        name='key_embed_b',\n",
        "                        initializer='zeros',\n",
        "                        trainable=True\n",
        "        )\n",
        "        self.key_to_scalar_w = self.add_weight(\n",
        "                        shape=(self.key_size, 1),\n",
        "                        name='key_to_scalar_w',\n",
        "                        initializer='glorot_uniform',\n",
        "                        trainable=True\n",
        "        )\n",
        "        self.key_to_scalar_b = self.add_weight(\n",
        "                        shape=(1,),\n",
        "                        name='key_to_scalar_b',\n",
        "                        initializer='zeros',\n",
        "                        trainable=True\n",
        "        )\n",
        "        self.value_embed_w = self.add_weight(\n",
        "                        shape=(self.input_dim, self.value_size),\n",
        "                        name='value_embed_w',\n",
        "                        initializer='glorot_uniform',\n",
        "                        trainable=True\n",
        "        )\n",
        "        self.value_embed_b = self.add_weight(\n",
        "                        shape=(self.value_size,),\n",
        "                        name='value_embed_b',\n",
        "                        initializer='zeros',\n",
        "                        trainable=True\n",
        "        )\n",
        "\n",
        "        super(KVAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        input_tensor = inputs  # (batch_size, timestamp, input_dim)\n",
        "        assert(len(input_tensor.shape) == 3)\n",
        "        assert(input_tensor.shape[1] == self.timestamps)\n",
        "        assert(input_tensor.shape[2] == self.input_dim)\n",
        "\n",
        "        # K = tanh(W_emb * input_tensor + b_emb).\n",
        "        K = tf.reshape(input_tensor, [-1, self.input_dim])\n",
        "        K = tf.nn.xw_plus_b(K, self.key_embed_w, self.key_embed_b)\n",
        "        K = tf.tanh(K)  # K.shape = (batch * timestamp, key_size)\n",
        "\n",
        "        # Further encode the key into a single scalar for each timestamp.\n",
        "        K = tf.nn.xw_plus_b(K, self.key_to_scalar_w, self.key_to_scalar_b)\n",
        "        K = tf.tanh(K)  # K.shape = (batch * timestamp, 1)\n",
        "        K = tf.reshape(K, [-1, self.timestamps])\n",
        "        # K.shape = (batch_size, timestamp)\n",
        "\n",
        "        # Apply softmax to the Key tensor.\n",
        "        assert(len(K.shape) == 2)\n",
        "        assert(K.shape[1] == self.timestamps)\n",
        "        P = tf.nn.softmax(K)  # P.shape (batch_size, timestamps)\n",
        "        assert(P.shape[1:] == K.shape[1:])\n",
        "        if self.return_attention_scores:\n",
        "            return P\n",
        "\n",
        "        # Build the Value vector (key part is completed, we have P).\n",
        "        # V = tanh(W_emb2 * input_tensor + b_emb2).\n",
        "        V = tf.reshape(input_tensor, [-1, self.input_dim])\n",
        "        V = tf.nn.xw_plus_b(V, self.value_embed_w, self.value_embed_b)\n",
        "        V = tf.nn.relu(V)  # V.shape = (batch * timestamp, value_size)\n",
        "        V = tf.reshape(V, [-1, self.timestamps, self.value_size])\n",
        "        # V.shape = (batch_size, timestamp, value_size)\n",
        "\n",
        "        # Perform the weighted sum.\n",
        "        P = tf.expand_dims(P, 1)\n",
        "        # P.shape = (batch_size, 1, timestamps)\n",
        "        # V.shape = (batch_size, timestamps, value_size)\n",
        "\n",
        "        out = tf.matmul(P, V)\n",
        "        assert(len(out.shape) == 3)\n",
        "        assert(out.shape[1] == 1)\n",
        "        out = tf.squeeze(out, axis=1)\n",
        "        assert(out.shape[1] == self.value_size)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert(isinstance(input_shape, tuple))\n",
        "        assert(len(input_shape) == 3)\n",
        "        if self.return_attention_scores:\n",
        "            return (input_shape[0], self.timestamps)\n",
        "        return (input_shape[0], self.value_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw1PSa2XDKdM"
      },
      "source": [
        "## Arch.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m67r-Rboyxe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e7cafc0-a1db-435b-a861-88a1674c46b4"
      },
      "source": [
        "# from arch.py\n",
        "\n",
        "def get_model():\n",
        "  answer_a = Input(shape=(DOC_QUANTITY , NUM_SCORES), name=\"answer_a\") \n",
        "  answer_b = Input(shape=(DOC_QUANTITY , NUM_SCORES), name=\"answer_b\") \n",
        "  answer_c = Input(shape=(DOC_QUANTITY , NUM_SCORES), name=\"answer_c\") \n",
        "  answer_d = Input(shape=(DOC_QUANTITY , NUM_SCORES), name=\"answer_d\") \n",
        "  # These layers are shared for each answer.\n",
        "  # apply a layer to every temporal slice of an input\n",
        "  #  The input should be at least 3D, and the dimension of index one\n",
        "  #  will be considered to be the temporal dimension.\n",
        "  encoder_layer1 = TimeDistributed(\n",
        "                      Dense(32, activation='tanh', name=\"dense_1\"),\n",
        "                      name=\"time_distributed_1\"\n",
        "  )\n",
        "  dropout_layer1 = SpatialDropout1D(0.25, name=\"spatial_dropout_1\")\n",
        "  # implementing lstm\n",
        "  # input_dim = 3\n",
        "  hidden_dim = 32\n",
        "  # n_layers = 100\n",
        "  lstm_layer = LSTM(hidden_dim, return_sequences=True, dropout = 0.15) #do it in keras!!!\n",
        "  # to_scalar_layer = KVAttention(\n",
        "  #                     key_size=64, value_size=8, name=\"att\",\n",
        "  #                     return_attention_scores=return_attention_scores\n",
        "  # )\n",
        "  def encode_answer(answer):\n",
        "    x = encoder_layer1(answer)\n",
        "    x = dropout_layer1(x)\n",
        "    x = lstm_layer(x)\n",
        "  # x = to_scalar_layer(x)\n",
        "    return x\n",
        "  a = encode_answer(answer_a)\n",
        "  b = encode_answer(answer_b)\n",
        "  c = encode_answer(answer_c)\n",
        "  d = encode_answer(answer_d)\n",
        "  y = Concatenate(axis=-1, name=\"concatenate_answers\")([a, b, c, d])\n",
        "  # if return_attention_scores:\n",
        "  #   output = y\n",
        "  # else:\n",
        "  y = Dense(32, activation='relu', name=\"dense_2\")(y)\n",
        "  y = Dropout(0.1, name=\"dropout_1\")(y)\n",
        "  y = Dense(32, activation='relu', name=\"dense_3\")(y)\n",
        "  y = Dropout(0.1, name=\"dropout_2\")(y)\n",
        "  y = Dense(32, activation='relu', name=\"dense_4\")(y)\n",
        "  print(y.shape)\n",
        "  output = Dense(4, activation='softmax', name=\"dense_5\")(y)\n",
        "  print(output.shape)\n",
        "\n",
        "  model = Model(inputs=[answer_a, answer_b, answer_c, answer_d],\n",
        "                    outputs=[output])\n",
        "  return model\n",
        "get_model()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 2, 32)\n",
            "(None, 2, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f398b69a050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ujBqXtvzDxH"
      },
      "source": [
        "## Setup Model Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxOhY7xJzCOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "931c0339-2668-45d7-e35c-a57a8739d57e"
      },
      "source": [
        "# from train.py\n",
        "def main():\n",
        "    # parser = argparse.ArgumentParser()\n",
        "    # parser.add_argument('-n', '--top_n', type=int,\n",
        "    #                     required=False, default=TOP_N,\n",
        "    #                     help='Number of documents to use.')\n",
        "    # FLAGS, _ = parser.parse_known_args()\n",
        "    # top_n = FLAGS.top_n\n",
        "\n",
        "    # train_dataset = utils.read_dataset(TRAIN_DATA_PATH, top_n)\n",
        "    # train_dataset = utils.augment_with_permutations(train_dataset)\n",
        "    # train_data, train_labels = utils.to_numpy(train_dataset, top_n)\n",
        "    train_data, train_labels = create_random_traindata(4000)\n",
        "    # del train_dataset\n",
        "\n",
        "    # val_dataset = utils.read_dataset(VAL_DATA_PATH, top_n)\n",
        "    # val_data, val_labels = utils.to_numpy(val_dataset, top_n)\n",
        "    val_data, val_labels = create_random_traindata(700)\n",
        "    # del val_dataset\n",
        "\n",
        "    model = get_model()\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['acc'])\n",
        "    model.summary()\n",
        "\n",
        "    filepath = os.path.join(\n",
        "                    MODELS_DIR,\n",
        "                    \"model-\" + str(uuid.uuid4()) +\n",
        "                    \"-{epoch:04d}-{val_loss:.4f}-{val_acc:.4f}.hdf5\"\n",
        "    )\n",
        "    save_model = ModelCheckpoint(filepath, monitor='val_acc', verbose=0,\n",
        "                                 save_best_only=False, mode='max')\n",
        "    model.fit(\n",
        "            train_data, train_labels,\n",
        "            validation_data=(val_data, val_labels),\n",
        "            batch_size=128,\n",
        "            epochs=75,\n",
        "            verbose=1,\n",
        "            callbacks=[save_model]\n",
        "    )\n",
        "#execute    \n",
        "main()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 2, 32)\n",
            "(None, 2, 4)\n",
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "answer_a (InputLayer)           [(None, 2, 3)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "answer_b (InputLayer)           [(None, 2, 3)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "answer_c (InputLayer)           [(None, 2, 3)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "answer_d (InputLayer)           [(None, 2, 3)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 2, 32)        128         answer_a[0][0]                   \n",
            "                                                                 answer_b[0][0]                   \n",
            "                                                                 answer_c[0][0]                   \n",
            "                                                                 answer_d[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout_1 (SpatialDropo (None, 2, 32)        0           time_distributed_1[0][0]         \n",
            "                                                                 time_distributed_1[1][0]         \n",
            "                                                                 time_distributed_1[2][0]         \n",
            "                                                                 time_distributed_1[3][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lstm_11 (LSTM)                  (None, 2, 32)        8320        spatial_dropout_1[0][0]          \n",
            "                                                                 spatial_dropout_1[1][0]          \n",
            "                                                                 spatial_dropout_1[2][0]          \n",
            "                                                                 spatial_dropout_1[3][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_answers (Concatenat (None, 2, 128)       0           lstm_11[0][0]                    \n",
            "                                                                 lstm_11[1][0]                    \n",
            "                                                                 lstm_11[2][0]                    \n",
            "                                                                 lstm_11[3][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2, 32)        4128        concatenate_answers[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2, 32)        0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2, 32)        1056        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 2, 32)        0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 2, 32)        1056        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 2, 4)         132         dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 14,820\n",
            "Trainable params: 14,820\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/75\n",
            "32/32 [==============================] - 9s 67ms/step - loss: 1.3867 - acc: 0.2611 - val_loss: 1.3860 - val_acc: 0.2379\n",
            "Epoch 2/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3860 - acc: 0.2582 - val_loss: 1.3861 - val_acc: 0.2493\n",
            "Epoch 3/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3862 - acc: 0.2552 - val_loss: 1.3866 - val_acc: 0.2493\n",
            "Epoch 4/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3829 - acc: 0.2695 - val_loss: 1.3873 - val_acc: 0.2579\n",
            "Epoch 5/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3848 - acc: 0.2691 - val_loss: 1.3881 - val_acc: 0.2386\n",
            "Epoch 6/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3829 - acc: 0.2784 - val_loss: 1.3896 - val_acc: 0.2393\n",
            "Epoch 7/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3822 - acc: 0.2803 - val_loss: 1.3911 - val_acc: 0.2457\n",
            "Epoch 8/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3835 - acc: 0.2796 - val_loss: 1.3923 - val_acc: 0.2457\n",
            "Epoch 9/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3813 - acc: 0.2730 - val_loss: 1.3931 - val_acc: 0.2586\n",
            "Epoch 10/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3822 - acc: 0.2693 - val_loss: 1.3935 - val_acc: 0.2629\n",
            "Epoch 11/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3764 - acc: 0.2908 - val_loss: 1.3941 - val_acc: 0.2686\n",
            "Epoch 12/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3774 - acc: 0.2886 - val_loss: 1.3943 - val_acc: 0.2643\n",
            "Epoch 13/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3791 - acc: 0.2836 - val_loss: 1.3958 - val_acc: 0.2636\n",
            "Epoch 14/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3747 - acc: 0.2942 - val_loss: 1.3986 - val_acc: 0.2614\n",
            "Epoch 15/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3717 - acc: 0.2980 - val_loss: 1.3975 - val_acc: 0.2636\n",
            "Epoch 16/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3756 - acc: 0.2967 - val_loss: 1.3981 - val_acc: 0.2614\n",
            "Epoch 17/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3692 - acc: 0.2880 - val_loss: 1.4023 - val_acc: 0.2479\n",
            "Epoch 18/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3694 - acc: 0.3024 - val_loss: 1.4011 - val_acc: 0.2671\n",
            "Epoch 19/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3709 - acc: 0.3033 - val_loss: 1.4043 - val_acc: 0.2436\n",
            "Epoch 20/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3656 - acc: 0.3188 - val_loss: 1.4065 - val_acc: 0.2500\n",
            "Epoch 21/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3652 - acc: 0.3079 - val_loss: 1.4086 - val_acc: 0.2421\n",
            "Epoch 22/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3635 - acc: 0.3095 - val_loss: 1.4095 - val_acc: 0.2493\n",
            "Epoch 23/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3608 - acc: 0.3106 - val_loss: 1.4128 - val_acc: 0.2471\n",
            "Epoch 24/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3561 - acc: 0.3266 - val_loss: 1.4127 - val_acc: 0.2407\n",
            "Epoch 25/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3553 - acc: 0.3255 - val_loss: 1.4161 - val_acc: 0.2457\n",
            "Epoch 26/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3542 - acc: 0.3265 - val_loss: 1.4171 - val_acc: 0.2407\n",
            "Epoch 27/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3531 - acc: 0.3344 - val_loss: 1.4187 - val_acc: 0.2471\n",
            "Epoch 28/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3508 - acc: 0.3378 - val_loss: 1.4218 - val_acc: 0.2407\n",
            "Epoch 29/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3553 - acc: 0.3334 - val_loss: 1.4216 - val_acc: 0.2450\n",
            "Epoch 30/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3459 - acc: 0.3371 - val_loss: 1.4263 - val_acc: 0.2457\n",
            "Epoch 31/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3456 - acc: 0.3418 - val_loss: 1.4281 - val_acc: 0.2450\n",
            "Epoch 32/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3436 - acc: 0.3384 - val_loss: 1.4302 - val_acc: 0.2350\n",
            "Epoch 33/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3426 - acc: 0.3386 - val_loss: 1.4324 - val_acc: 0.2407\n",
            "Epoch 34/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3407 - acc: 0.3558 - val_loss: 1.4353 - val_acc: 0.2436\n",
            "Epoch 35/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3473 - acc: 0.3368 - val_loss: 1.4319 - val_acc: 0.2471\n",
            "Epoch 36/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3450 - acc: 0.3338 - val_loss: 1.4342 - val_acc: 0.2386\n",
            "Epoch 37/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3356 - acc: 0.3570 - val_loss: 1.4370 - val_acc: 0.2493\n",
            "Epoch 38/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3312 - acc: 0.3531 - val_loss: 1.4428 - val_acc: 0.2457\n",
            "Epoch 39/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3323 - acc: 0.3585 - val_loss: 1.4425 - val_acc: 0.2429\n",
            "Epoch 40/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3268 - acc: 0.3596 - val_loss: 1.4418 - val_acc: 0.2407\n",
            "Epoch 41/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3364 - acc: 0.3504 - val_loss: 1.4437 - val_acc: 0.2379\n",
            "Epoch 42/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3226 - acc: 0.3665 - val_loss: 1.4466 - val_acc: 0.2421\n",
            "Epoch 43/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3241 - acc: 0.3662 - val_loss: 1.4510 - val_acc: 0.2500\n",
            "Epoch 44/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3238 - acc: 0.3641 - val_loss: 1.4470 - val_acc: 0.2600\n",
            "Epoch 45/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3143 - acc: 0.3725 - val_loss: 1.4472 - val_acc: 0.2486\n",
            "Epoch 46/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3189 - acc: 0.3670 - val_loss: 1.4553 - val_acc: 0.2507\n",
            "Epoch 47/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3191 - acc: 0.3628 - val_loss: 1.4548 - val_acc: 0.2421\n",
            "Epoch 48/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3249 - acc: 0.3603 - val_loss: 1.4521 - val_acc: 0.2450\n",
            "Epoch 49/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3194 - acc: 0.3574 - val_loss: 1.4551 - val_acc: 0.2443\n",
            "Epoch 50/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3054 - acc: 0.3791 - val_loss: 1.4621 - val_acc: 0.2414\n",
            "Epoch 51/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3131 - acc: 0.3754 - val_loss: 1.4605 - val_acc: 0.2486\n",
            "Epoch 52/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3089 - acc: 0.3730 - val_loss: 1.4631 - val_acc: 0.2357\n",
            "Epoch 53/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3102 - acc: 0.3757 - val_loss: 1.4692 - val_acc: 0.2450\n",
            "Epoch 54/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3011 - acc: 0.3821 - val_loss: 1.4648 - val_acc: 0.2407\n",
            "Epoch 55/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3101 - acc: 0.3796 - val_loss: 1.4706 - val_acc: 0.2543\n",
            "Epoch 56/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.3016 - acc: 0.3717 - val_loss: 1.4655 - val_acc: 0.2493\n",
            "Epoch 57/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3088 - acc: 0.3668 - val_loss: 1.4728 - val_acc: 0.2421\n",
            "Epoch 58/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3001 - acc: 0.3833 - val_loss: 1.4754 - val_acc: 0.2336\n",
            "Epoch 59/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.2973 - acc: 0.3886 - val_loss: 1.4757 - val_acc: 0.2486\n",
            "Epoch 60/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.2888 - acc: 0.3983 - val_loss: 1.4781 - val_acc: 0.2493\n",
            "Epoch 61/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.2946 - acc: 0.3868 - val_loss: 1.4730 - val_acc: 0.2450\n",
            "Epoch 62/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.2887 - acc: 0.3991 - val_loss: 1.4829 - val_acc: 0.2493\n",
            "Epoch 63/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.2978 - acc: 0.3717 - val_loss: 1.4843 - val_acc: 0.2429\n",
            "Epoch 64/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.2852 - acc: 0.3956 - val_loss: 1.4853 - val_acc: 0.2457\n",
            "Epoch 65/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.2927 - acc: 0.3891 - val_loss: 1.4893 - val_acc: 0.2343\n",
            "Epoch 66/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.2861 - acc: 0.3928 - val_loss: 1.4861 - val_acc: 0.2350\n",
            "Epoch 67/75\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.2838 - acc: 0.3874 - val_loss: 1.4913 - val_acc: 0.2414\n",
            "Epoch 68/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.2758 - acc: 0.3942 - val_loss: 1.4844 - val_acc: 0.2450\n",
            "Epoch 69/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.2867 - acc: 0.3881 - val_loss: 1.4890 - val_acc: 0.2279\n",
            "Epoch 70/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.2839 - acc: 0.3938 - val_loss: 1.4913 - val_acc: 0.2286\n",
            "Epoch 71/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.2826 - acc: 0.3907 - val_loss: 1.4928 - val_acc: 0.2393\n",
            "Epoch 72/75\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.2863 - acc: 0.3880 - val_loss: 1.4853 - val_acc: 0.2329\n",
            "Epoch 73/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.2796 - acc: 0.4047 - val_loss: 1.4953 - val_acc: 0.2300\n",
            "Epoch 74/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.2648 - acc: 0.4142 - val_loss: 1.5000 - val_acc: 0.2307\n",
            "Epoch 75/75\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.2685 - acc: 0.4047 - val_loss: 1.5073 - val_acc: 0.2329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feQos7WM0noP"
      },
      "source": [
        "## Run trained Model on Validaion Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63kjlNdzvtZ7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FZFMP1-0yEt"
      },
      "source": [
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-n', '--top_n', type=int,\n",
        "                        required=False, default=TOP_N,\n",
        "                        help='Number of documents to use.')\n",
        "    FLAGS, _ = parser.parse_known_args()\n",
        "    top_n = FLAGS.top_n\n",
        "\n",
        "    train_dataset = utils.read_dataset(TRAIN_DATA_PATH, top_n)\n",
        "    train_dataset = utils.augment_with_permutations(train_dataset)\n",
        "    train_data, train_labels = utils.to_numpy(train_dataset, top_n)\n",
        "    del train_dataset\n",
        "\n",
        "    val_dataset = utils.read_dataset(VAL_DATA_PATH, top_n)\n",
        "    val_data, val_labels = utils.to_numpy(val_dataset, top_n)\n",
        "    del val_dataset\n",
        "\n",
        "    model = arch.get_model(top_n)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['acc'])\n",
        "    model.summary()\n",
        "\n",
        "    filepath = os.path.join(\n",
        "                    MODELS_DIR,\n",
        "                    \"model-\" + str(uuid.uuid4()) +\n",
        "                    \"-{epoch:04d}-{val_loss:.4f}-{val_acc:.4f}.hdf5\"\n",
        "    )\n",
        "    save_model = ModelCheckpoint(filepath, monitor='val_acc', verbose=0,\n",
        "                                 save_best_only=False, mode='max')\n",
        "    model.fit(\n",
        "            train_data, train_labels,\n",
        "            validation_data=(val_data, val_labels),\n",
        "            batch_size=128,\n",
        "            epochs=75,\n",
        "            verbose=1,\n",
        "            callbacks=[save_model]\n",
        "    )"
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}