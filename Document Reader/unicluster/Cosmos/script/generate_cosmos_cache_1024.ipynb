{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spare-duration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 15 18:51:13 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    39W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    38W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    40W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    41W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1780      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    1   N/A  N/A      1780      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    2   N/A  N/A      1780      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    3   N/A  N/A      1780      G   /usr/libexec/Xorg                   8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loving-nickel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib64/python3.6/site-packages', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages/IPython/extensions', '/pfs/data5/home/st/st_us-051200/st_st169719/.ipython', '/pfs/data5/home/st/st_us-051200/st_st169719/third_party']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/pfs/data5/home/st/st_us-051200/st_st169719/third_party\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "macro-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import csv\n",
    "import lineflow as lf\n",
    "import json_lines\n",
    "from functools import partial\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "from transformers import AlbertForMultipleChoice, AlbertTokenizer, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "double-experiment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/script\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "timely-strain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-12 20:43:03--  https://raw.githubusercontent.com/wilburOne/cosmosqa/master/data/valid.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2128345 (2.0M) [text/plain]\n",
      "Saving to: ‘valid.csv’\n",
      "\n",
      "valid.csv           100%[===================>]   2.03M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2021-06-12 20:43:03 (29.6 MB/s) - ‘valid.csv’ saved [2128345/2128345]\n",
      "\n",
      "--2021-06-12 20:43:04--  https://raw.githubusercontent.com/wilburOne/cosmosqa/master/data/train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16660449 (16M) [text/plain]\n",
      "Saving to: ‘train.csv’\n",
      "\n",
      "train.csv           100%[===================>]  15.89M  55.4MB/s    in 0.3s    \n",
      "\n",
      "2021-06-12 20:43:05 (55.4 MB/s) - ‘train.csv’ saved [16660449/16660449]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd dataset && wget https://raw.githubusercontent.com/wilburOne/cosmosqa/master/data/valid.csv\n",
    "!cd dataset && wget https://raw.githubusercontent.com/wilburOne/cosmosqa/master/data/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quality-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "south-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "virtual-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datas = []\n",
    "with open('../dataset/valid.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for sample in reader:\n",
    "      _id = sample[0]\n",
    "      _article = sample[1]\n",
    "      _question = sample[2]\n",
    "      _options = []\n",
    "      _answer = sample[-1]\n",
    "      _options.append(sample[3])\n",
    "      _options.append(sample[4])\n",
    "      _options.append(sample[5])\n",
    "      _options.append(sample[6])\n",
    "\n",
    "      data = {\n",
    "              \"id\": _id,\n",
    "              \"article\": _article,\n",
    "              \"options\": _options,\n",
    "              \"question\": _question,\n",
    "              \"answer\": _answer\n",
    "              }\n",
    "      val_datas.append(data)\n",
    "val_dataset = lf.Dataset(val_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "global-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datas = []\n",
    "with open('../dataset/train.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for sample in reader:\n",
    "      _id = sample[0]\n",
    "      _article = sample[1]\n",
    "      _question = sample[2]\n",
    "      _options = []\n",
    "      _answer = sample[-1]\n",
    "      _options.append(sample[3])\n",
    "      _options.append(sample[4])\n",
    "      _options.append(sample[5])\n",
    "      _options.append(sample[6])\n",
    "\n",
    "      data = {\n",
    "              \"id\": _id,\n",
    "              \"article\": _article,\n",
    "              \"options\": _options,\n",
    "              \"question\": _question,\n",
    "              \"answer\": _answer\n",
    "              }\n",
    "      train_datas.append(data)\n",
    "train_dataset = lf.Dataset(train_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "average-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1024\n",
    "NUM_LABELS = 4\n",
    "label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accomplished-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tokenizer: AlbertTokenizer, x: Dict) -> Dict:\n",
    "\n",
    "    choices_features = []\n",
    "\n",
    "    option: str\n",
    "    for option in x[\"options\"]:\n",
    "        text_a = x[\"article\"]\n",
    "        text_b = x[\"question\"] + \" \" + option\n",
    "\n",
    "        inputs = tokenizer.encode_plus(\n",
    "                text_a,\n",
    "                text_b,\n",
    "                add_special_tokens=True,\n",
    "                max_length=MAX_LEN\n",
    "                )\n",
    "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        pad_token_id = tokenizer.pad_token_id\n",
    "        padding_length = MAX_LEN - len(input_ids)\n",
    "        input_ids = input_ids + ([pad_token_id] * padding_length)\n",
    "        attention_mask = attention_mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([pad_token_id] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(input_ids), MAX_LEN)\n",
    "        assert len(attention_mask) == MAX_LEN, \"Error with input length {} vs {}\".format(len(attention_mask), MAX_LEN)\n",
    "        assert len(token_type_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(token_type_ids), MAX_LEN)\n",
    "\n",
    "        choices_features.append({\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"token_type_ids\": token_type_ids,\n",
    "            })\n",
    "\n",
    "    labels = int(x[\"answer\"])\n",
    "    label = torch.tensor(labels).long()\n",
    "\n",
    "    return {\n",
    "            \"id\": x[\"id\"],\n",
    "            \"label\": label,\n",
    "            \"input_ids\": torch.tensor([cf[\"input_ids\"] for cf in choices_features]),\n",
    "            \"attention_mask\": torch.tensor([cf[\"attention_mask\"] for cf in choices_features]),\n",
    "            \"token_type_ids\": torch.tensor([cf[\"token_type_ids\"] for cf in choices_features]),\n",
    "            }\n",
    "\n",
    "\n",
    "def get_dataloader(tokenizer):\n",
    "    preprocessor = partial(preprocess, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "            train_dataset.map(preprocessor).save(\"/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/dataset/CacheFiles/MAX_LEN1024/BatchSize32/train_cosmos.cache\"),\n",
    "            sampler=RandomSampler(train_dataset),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=40\n",
    "            )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "            val_dataset.map(preprocessor).save(\"/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/dataset/CacheFiles/MAX_LEN1024/BatchSize32/val_cosmos.cache\"),\n",
    "            sampler=SequentialSampler(val_dataset),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=40\n",
    "            )\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "professional-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "underlying-price",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to /pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/dataset/CacheFiles/BatchSize32/train_cosmos.cache...\n",
      "Saving data to /pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/dataset/CacheFiles/BatchSize32/val_cosmos.cache...\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = get_dataloader(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-means",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
