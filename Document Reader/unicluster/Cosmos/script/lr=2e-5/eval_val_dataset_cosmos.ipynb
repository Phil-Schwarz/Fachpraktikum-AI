{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "derived-narrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib64/python3.6/site-packages', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages/IPython/extensions', '/pfs/data5/home/st/st_us-051200/st_st169719/.ipython', '/pfs/data5/home/st/st_us-051200/st_st169719/third_party']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/pfs/data5/home/st/st_us-051200/st_st169719/third_party\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "excessive-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import lineflow as lf\n",
    "from transformers import AlbertForMultipleChoice, AlbertTokenizer, AdamW\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "import json_lines\n",
    "from transformers import AlbertConfig\n",
    "import pickle\n",
    "from pytorch_lightning.metrics import functional as FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "backed-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed seed\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "streaming-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed seed for generating dataset\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "public-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conditional-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataloader_from_cache(cachedir :str):\n",
    "    cachedir = Path(cachedir)\n",
    "    \n",
    "    test_file_name = \"val_cosmos.cache\"\n",
    "    test_path = Path(cachedir / test_file_name)\n",
    "    if test_path.exists():\n",
    "        print(f'Loading data from {test_file_name}...')\n",
    "        with test_path.open('rb') as f:\n",
    "            test_cache = pickle.load(f)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(test_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,#new here, used for fixed seed when generating dataloader\n",
    "            num_workers=80 # new here, 80 is chosen when using 4 gpus in unicluster\n",
    "            )\n",
    "\n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "industrial-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, test_dataloader):\n",
    "        super(TestModel, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self._test_dataloader = test_dataloader\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "presidential-badge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from val_cosmos.cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 80 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = load_test_dataloader_from_cache('/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/dataset/CacheFiles/MAX_LEN_512/BatchSize32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "convenient-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = '/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/Ex01/ex01-albert-cosmos-epoch=02-val_loss_epoch=1.10.ckpt'\n",
    "path_2 = '/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/Ex02/ex02-albert-cosmos-epoch=00-val_loss_epoch=1.110.ckpt'\n",
    "path_3 = '/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/Ex02/ex02-albert-cosmos-epoch=01-val_loss_epoch=1.008.ckpt'\n",
    "path_4 = '/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/Ex02/ex02-albert-cosmos-epoch=02-val_acc_epoch=0.583.ckpt'\n",
    "path_5 = '/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/Ex02/ex02-albert-cosmos-epoch=03-val_acc_epoch=0.588.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "chronic-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = []\n",
    "path_list.append(path_1)\n",
    "path_list.append(path_2)\n",
    "path_list.append(path_3)\n",
    "path_list.append(path_4)\n",
    "path_list.append(path_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aboriginal-gathering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/Ex01/ex01-albert-cosmos-epoch=02-val_loss_epoch=1.10.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de698fc44344f7c9b8966468659756e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.3333333432674408, 'test_acc_epoch': 0.5380821824073792}\n",
      "--------------------------------------------------------------------------------\n",
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/Ex02/ex02-albert-cosmos-epoch=00-val_loss_epoch=1.110.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31acc8a371f439081c499fe242c1b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.3333333432674408, 'test_acc_epoch': 0.5394225120544434}\n",
      "--------------------------------------------------------------------------------\n",
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/Ex02/ex02-albert-cosmos-epoch=01-val_loss_epoch=1.008.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411a7b8d9227451ba2cd1aa858fb1547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.3333333432674408, 'test_acc_epoch': 0.5553839206695557}\n",
      "--------------------------------------------------------------------------------\n",
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/Ex02/ex02-albert-cosmos-epoch=02-val_acc_epoch=0.583.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752ce7b88a214b9ba1b63970a43a5d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.6666666865348816, 'test_acc_epoch': 0.5746909976005554}\n",
      "--------------------------------------------------------------------------------\n",
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/Ex02/ex02-albert-cosmos-epoch=03-val_acc_epoch=0.588.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb403d7f90be465daf77764d0832c3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.6666666865348816, 'test_acc_epoch': 0.5934354066848755}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# use AlbertModel, donot use AlbertforMultiChoice\n",
    "config = AlbertConfig.from_pretrained('albert-base-v2')\n",
    "\n",
    "# load checkpoint file which you want to use\n",
    "for path in path_list:\n",
    "    print('Model in path:' + path)\n",
    "    checkpoint = torch.load(path)\n",
    "    new_checkpoint = {}\n",
    "\n",
    "    for key in checkpoint['state_dict'].keys():\n",
    "      if 'model' in key:\n",
    "        new_key = key[6:]\n",
    "        new_checkpoint[new_key] = checkpoint['state_dict'][key]\n",
    "      else:\n",
    "        new_checkpoint[key] = checkpoint['state_dict'][key]\n",
    "        \n",
    "    m = AlbertForMultipleChoice.from_pretrained(pretrained_model_name_or_path= None, config=config, state_dict=new_checkpoint)\n",
    "    trainer_for_test = pl.Trainer(gpus=4, accelerator='dp')\n",
    "    model_for_test = TestModel(m, test_dataloader)\n",
    "    trainer_for_test.test(model=model_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-private",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
