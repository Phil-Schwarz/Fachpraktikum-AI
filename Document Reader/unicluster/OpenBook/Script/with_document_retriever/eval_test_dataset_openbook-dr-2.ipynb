{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "signed-recording",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/2021-06-25/lib/python3.6/site-packages', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/2021-06-25/lib64/python3.6/site-packages', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/2021-06-25/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/2021-06-25/lib/python3.6/site-packages/IPython/extensions', '/pfs/data5/home/st/st_us-051200/st_st169719/.ipython', '/pfs/data5/home/st/st_us-051200/st_st169719/third_party']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/pfs/data5/home/st/st_us-051200/st_st169719/third_party\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72b378b-f186-4202-a4ae-6f50c830a1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  5 14:17:19 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:15:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    40W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:16:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    43W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    41W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    42W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1759      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    1   N/A  N/A      1759      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    2   N/A  N/A      1759      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    3   N/A  N/A      1759      G   /usr/libexec/Xorg                   8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "published-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import lineflow as lf\n",
    "from transformers import AlbertForMultipleChoice, AlbertTokenizer, AdamW\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "import json_lines\n",
    "from transformers import AlbertConfig\n",
    "import pickle\n",
    "from pytorch_lightning.metrics import functional as FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "planned-monday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "pl.utilities.seed.seed_everything(seed=0, workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thrown-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed seed for generating dataset\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exceptional-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "judicial-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloader_from_cache(cachedir :str):\n",
    "    cachedir = Path(cachedir)\n",
    "\n",
    "    train_file_name = \"train_cosmos.cache\"\n",
    "    train_path = Path(cachedir / train_file_name)\n",
    "    if train_path.exists():\n",
    "        print(f'Loading data from {train_file_name}...')\n",
    "        with train_path.open('rb') as f:\n",
    "            train_cache = pickle.load(f)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(train_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=40\n",
    "            )\n",
    "\n",
    "    val_file_name = \"val_cosmos.cache\"\n",
    "    val_path = Path(cachedir / val_file_name)\n",
    "    if val_path.exists():\n",
    "        print(f'Loading data from {val_file_name}...')\n",
    "        with val_path.open('rb') as f:\n",
    "            val_cache = pickle.load(f)\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(val_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=40\n",
    "            )\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "superb-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, test_dataloader):\n",
    "        super(TestModel, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self._test_dataloader = test_dataloader\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "modular-wales",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from train_cosmos.cache...\n",
      "Loading data from val_cosmos.cache...\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = load_dataloader_from_cache('/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/dataset/CacheFiles/MAX_LEN_512/BatchSize32/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accurate-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path_list = glob.glob(\"/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/adaptive_lr/*/*/*.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-seventh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/Cosmos/Checkpoints/adaptive_lr/lr=2e-6/Ex02/ex02-albert-cosmos-epoch=00-val_loss_epoch=1.13.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3702903ccf4bc7894ff25943862288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use AlbertModel, donot use AlbertforMultiChoice\n",
    "config = AlbertConfig.from_pretrained('albert-base-v2')\n",
    "\n",
    "# load checkpoint file which you want to use\n",
    "for path in path_list:\n",
    "    print('Model in path:' + path)\n",
    "    checkpoint = torch.load(path)\n",
    "    new_checkpoint = {}\n",
    "\n",
    "    for key in checkpoint['state_dict'].keys():\n",
    "      if 'model' in key:\n",
    "        new_key = key[6:]\n",
    "        new_checkpoint[new_key] = checkpoint['state_dict'][key]\n",
    "      else:\n",
    "        new_checkpoint[key] = checkpoint['state_dict'][key]\n",
    "        \n",
    "    m = AlbertForMultipleChoice.from_pretrained(pretrained_model_name_or_path= None, config=config, state_dict=new_checkpoint)\n",
    "    trainer_for_test = pl.Trainer(gpus=4, accelerator='dp')\n",
    "    model_for_test = TestModel(m, val_dataloader)\n",
    "    trainer_for_test.test(model=model_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b1f84-1fc6-4388-9739-6cd0d4cec0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
