{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adequate-twelve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 24 20:30:54 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    55W / 300W |   1531MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    54W / 300W |   1403MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    54W / 300W |   1427MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    55W / 300W |   1403MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1811      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    0   N/A  N/A   3913426      C   ...n/jupyter/base/bin/python     1519MiB |\n",
      "|    1   N/A  N/A      1811      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    1   N/A  N/A   3913426      C   ...n/jupyter/base/bin/python     1391MiB |\n",
      "|    2   N/A  N/A      1811      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    2   N/A  N/A   3913426      C   ...n/jupyter/base/bin/python     1415MiB |\n",
      "|    3   N/A  N/A      1811      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    3   N/A  N/A   3913426      C   ...n/jupyter/base/bin/python     1391MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reasonable-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd\n",
    "#!cd OpenBook && mkdir dataset\n",
    "#!mkdir third_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arranged-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet --target=/pfs/data5/home/st/st_us-051200/st_st169719/third_party pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "certified-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "textile-delight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib64/python3.6/site-packages', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages/IPython/extensions', '/pfs/data5/home/st/st_us-051200/st_st169719/.ipython', '/pfs/data5/home/st/st_us-051200/st_st169719/third_party']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/pfs/data5/home/st/st_us-051200/st_st169719/third_party\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "formed-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import lineflow as lf\n",
    "from transformers import AlbertForMultipleChoice, AlbertTokenizer, AdamW\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "import json_lines\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cross-shooting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "pl.utilities.seed.seed_everything(seed=0, workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reasonable-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "overhead-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "NUM_LABELS = 4\n",
    "label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "found-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloader_from_cache(cachedir :str):\n",
    "    cachedir = Path(cachedir)\n",
    "\n",
    "    train_file_name = \"cache4_train_ob.cache\"\n",
    "    train_path = Path(cachedir / train_file_name)\n",
    "    print(train_path)\n",
    "    if train_path.exists():\n",
    "        print(f'Loading data from {train_file_name}...')\n",
    "        with train_path.open('rb') as f:\n",
    "            train_cache = pickle.load(f)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(train_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=40\n",
    "            )\n",
    "\n",
    "    val_file_name = \"cache4_dev_ob.cache\"\n",
    "    val_path = Path(cachedir / val_file_name)\n",
    "    if val_path.exists():\n",
    "        print(f'Loading data from {val_file_name}...')\n",
    "        with val_path.open('rb') as f:\n",
    "            val_cache = pickle.load(f)\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(val_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=40\n",
    "            )\n",
    "    \n",
    "    test_file_name = \"cache4_test_ob.cache\"\n",
    "    test_path = Path(cachedir / test_file_name)\n",
    "    if test_path.exists():\n",
    "        print(f'Loading data from {val_file_name}...')\n",
    "        with test_path.open('rb') as f:\n",
    "            test_cache = pickle.load(f)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(test_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=40\n",
    "            )\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "arbitrary-printer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Script/Second_Experiment/start_learning_rate=3e-5\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "parental-house",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/st/st_us-051200/st_st169719/Philippe/Caches_New/cache4_train_ob.cache\n",
      "Loading data from cache4_train_ob.cache...\n",
      "Loading data from cache4_dev_ob.cache...\n",
      "Loading data from cache4_dev_ob.cache...\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = load_dataloader_from_cache(\"/pfs/data5/home/st/st_us-051200/st_st169719/Philippe/Caches_New/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "renewable-rwanda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "broke-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.metrics import functional as FM\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "artificial-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        model = AlbertForMultipleChoice.from_pretrained(\"albert-base-v2\", num_labels=NUM_LABELS)\n",
    "        self.model = model\n",
    "\n",
    "        self._train_dataloader = train_dataloader\n",
    "        self._val_dataloader = val_dataloader\n",
    "        self._test_dataloader = test_dataloader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        weight_decay = 0.0\n",
    "        adam_epsilon = 1e-8\n",
    "\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': weight_decay\n",
    "                },\n",
    "            {\n",
    "                'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.0,\n",
    "                }\n",
    "            ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, eps=adam_epsilon)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        # print(labels.size())\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "\n",
    "        self.log('train_loss', outputs.loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return outputs.loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "\n",
    "        self.log('val_loss', outputs.loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log('val_acc', acc, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "                \n",
    "        return acc\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        acc = self.validation_step(batch, batch_idx)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self._train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._val_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "impossible-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/pfs/data5/home/st/st_us-051200/st_st169719/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "suspended-theorem",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# saves a file like: my/path/albert-openbook-epoch=02-val_loss_epoch=0.32.ckpt\n",
    "# if you don't want to save checkpoint into google drive, change dirpath!!!\n",
    "loss_checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss_epoch',\n",
    "    dirpath= ROOT_DIR + 'OpenBook/Checkpoints/DR3e-5/Ex01',\n",
    "    # dirpath='/your/path/',\n",
    "    filename='dr_ex01-albert-openbook-{epoch:02d}-{val_loss_epoch:.3f}',\n",
    "    save_top_k=2,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "acc_checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc_epoch',\n",
    "    dirpath= ROOT_DIR + 'OpenBook/Checkpoints/DR3e-5/Ex01',\n",
    "    # dirpath='/your/path/',\n",
    "    filename='dr_ex01-albert-openbook-{epoch:02d}-{val_acc_epoch:.3f}',\n",
    "    save_top_k=2,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(gpus=4, max_epochs=10, callbacks=[loss_checkpoint_callback, acc_checkpoint_callback], accelerator='dp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "permanent-spain",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForMultipleChoice: ['predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.dense.weight']\n",
      "- This IS expected if you are initializing AlbertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForMultipleChoice were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pl_model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-python",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | AlbertForMultipleChoice | 11.7 M\n",
      "--------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.737    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e725f89e0a340f99aa401be23fe77d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/pfs/data5/home/st/st_us-051200/st_st169719/third_party/tensorboard/summary/writer/event_file_writer.py\", line 238, in run\n",
      "    self._record_writer.write(data)\n",
      "  File \"/pfs/data5/home/st/st_us-051200/st_st169719/third_party/tensorboard/summary/writer/record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"/pfs/data5/home/st/st_us-051200/st_st169719/third_party/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 531, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"/pfs/data5/home/st/st_us-051200/st_st169719/third_party/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 154, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"/pfs/data5/home/st/st_us-051200/st_st169719/third_party/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 158, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: b'/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Script/Second_Experiment/start_learning_rate=3e-5/lightning_logs/version_19604743/events.out.tfevents.1624559720.uc2n518.localdomain.3917836.0'\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9a221d1106428eaf5c75dadb83b6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "willing-timber",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3904e5bd383b43d9a410faa1297b734a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.4000000059604645,\n",
      " 'test_acc_epoch': 0.3673076927661896,\n",
      " 'val_acc': 0.4000000059604645,\n",
      " 'val_acc_epoch': 0.3673076927661896,\n",
      " 'val_loss': 1.5727283954620361,\n",
      " 'val_loss_epoch': 1.4024710655212402}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = trainer.test(test_dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "declared-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./lightning_logs ../../Checkpoints/DR1e-5/Ex01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-appreciation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
