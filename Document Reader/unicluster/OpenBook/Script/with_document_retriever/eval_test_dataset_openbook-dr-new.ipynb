{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "portuguese-rates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib64/python3.6/site-packages', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages/IPython/extensions', '/pfs/data5/home/st/st_us-051200/st_st169719/.ipython', '/pfs/data5/home/st/st_us-051200/st_st169719/third_party']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/pfs/data5/home/st/st_us-051200/st_st169719/third_party\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungry-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import lineflow as lf\n",
    "from transformers import AlbertForMultipleChoice, AlbertTokenizer, AdamW\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "import json_lines\n",
    "from transformers import AlbertConfig\n",
    "import pickle\n",
    "from pytorch_lightning.metrics import functional as FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pediatric-microwave",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixed seed\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "pl.utilities.seed.seed_everything(seed=0, workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "circular-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed seed for generating dataset\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worth-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interstate-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloader_from_cache(cachedir :str):\n",
    "    cachedir = Path(cachedir)\n",
    "    \n",
    "    test_file_name = \"cache4_test_ob.cache\"\n",
    "    test_path = Path(cachedir / test_file_name)\n",
    "    if test_path.exists():\n",
    "        print(f'Loading data from {test_file_name}...')\n",
    "        with test_path.open('rb') as f:\n",
    "            test_cache = pickle.load(f)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(test_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=40\n",
    "            )\n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reverse-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, test_dataloader):\n",
    "        super(TestModel, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self._test_dataloader = test_dataloader\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        print(\"labels:\", labels)\n",
    "        print(\"labels_hat\", labels_hat)\n",
    "        \n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assumed-phrase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from cache4_test_ob.cache...\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = load_dataloader_from_cache('/pfs/data5/home/st/st_us-051200/st_st169719/Philippe/Caches_New/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "danish-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path_list = glob.glob(\"/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/DR2e-5/*/*.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distant-introduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/DR2e-5/Ex03/dr_ex03-albert-openbook-epoch=02-val_acc_epoch=0.596.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e15d40bb7e4406dba4310d7d5acbb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: labels: labels: labels: tensor([1, 0, 2, 2, 2, 2, 2, 1], device='cuda:0')\n",
      "labels_hat tensor([0, 0, 2, 2, 2, 2, 1, 1], device='cuda:0')\n",
      "tensor([3, 1, 2, 1, 2, 0, 2, 3], device='cuda:1')\n",
      "labels_hat tensor([2, 2, 0, 1, 0, 0, 0, 1], device='cuda:2')tensor([1, 0, 0, 1, 2, 0, 3, 3], device='cuda:1')\n",
      "labels_hat \n",
      "tensor([2, 0, 0, 3, 2, 0, 0, 3], device='cuda:2')\n",
      "tensor([1, 1, 3, 0, 3, 1, 2, 3], device='cuda:3')\n",
      "labels_hat tensor([1, 1, 1, 1, 3, 1, 2, 0], device='cuda:3')\n",
      "labels: labels: labels: labels: tensor([1, 2, 0, 3, 0, 3, 2, 0], device='cuda:2')\n",
      "labels_hat tensor([1, 2, 2, 3, 1, 0, 3, 1], device='cuda:2')tensor([3, 3, 0, 3, 0, 0, 0, 0], device='cuda:1')\n",
      "\n",
      "labels_hat tensor([2, 3, 1, 1, 2, 1, 3, 0], device='cuda:1')\n",
      "tensor([2, 3, 1, 0, 2, 2, 0, 1], device='cuda:3')\n",
      "labels_hat tensor([1, 1, 2, 0, 2, 2, 2, 0], device='cuda:3')\n",
      "tensor([1, 0, 1, 0, 0, 3, 3, 0], device='cuda:0')\n",
      "labels_hat tensor([3, 3, 3, 2, 2, 2, 2, 0], device='cuda:0')\n",
      "labels: labels: labels: labels: tensor([2, 0, 0, 1, 3, 1, 3, 3], device='cuda:2')\n",
      "labels_hat tensor([2, 0, 2, 2, 0, 2, 1, 2], device='cuda:1')\n",
      "labels_hat tensor([2, 0, 2, 1, 3, 3, 2, 2], device='cuda:2')\n",
      "tensor([2, 0, 2, 0, 0, 2, 1, 1], device='cuda:1')\n",
      "tensor([2, 0, 0, 3, 2, 0, 2, 2], device='cuda:3')\n",
      "labels_hat tensor([3, 1, 0, 3, 1, 3, 2, 2], device='cuda:3')\n",
      "tensor([1, 2, 0, 0, 0, 3, 1, 2], device='cuda:0')\n",
      "labels_hat tensor([2, 2, 1, 0, 1, 3, 2, 2], device='cuda:0')\n",
      "labels: labels: labels: labels: tensor([1, 3, 1, 0, 3, 2, 2, 1], device='cuda:1')\n",
      "labels_hat tensor([2, 1, 1, 0, 3, 2, 2, 2], device='cuda:1')\n",
      "tensor([1, 2, 0, 2, 3, 3, 0, 1], device='cuda:2')\n",
      "labels_hat tensor([0, 3, 0, 3, 1, 0, 0, 3], device='cuda:3')\n",
      "labels_hat tensor([1, 2, 0, 1, 3, 3, 3, 1], device='cuda:2')\n",
      "tensor([3, 1, 0, 3, 1, 1, 0, 1], device='cuda:3')\n",
      "tensor([2, 1, 0, 2, 1, 1, 0, 3], device='cuda:0')\n",
      "labels_hat tensor([2, 1, 1, 2, 3, 3, 3, 3], device='cuda:0')\n",
      "labels: labels:labels:  labels: tensor([3, 1, 1, 0, 2, 0, 3, 3], device='cuda:1')\n",
      "labels_hat tensor([3, 3, 1, 1, 3, 0, 1, 3], device='cuda:1')\n",
      "tensor([0, 3, 0, 0, 0, 0, 2, 3], device='cuda:2')\n",
      "labels_hat tensor([1, 3, 2, 1, 0, 3, 3, 3], device='cuda:2')\n",
      "tensor([1, 2, 0, 1, 0, 2, 2, 1], device='cuda:3')\n",
      "labels_hat tensor([0, 3, 0, 2, 0, 2, 1, 1], device='cuda:3')\n",
      "tensor([1, 2, 1, 3, 2, 0, 3, 0], device='cuda:0')\n",
      "labels_hat tensor([1, 0, 2, 1, 2, 0, 0, 0], device='cuda:0')\n",
      "labels: labels: labels: labels: tensor([1, 0, 3, 1, 2, 2, 2, 2], device='cuda:2')\n",
      "labels_hat tensor([2, 1, 2, 0, 2, 0, 1, 1], device='cuda:1')\n",
      "labels_hat tensor([0, 0, 1, 3, 3, 2, 2, 2], device='cuda:2')\n",
      "tensor([3, 3, 2, 0, 3, 0, 3, 1], device='cuda:1')\n",
      "tensor([3, 0, 3, 2, 3, 2, 2, 1], device='cuda:3')\n",
      "labels_hat tensor([2, 0, 3, 2, 3, 3, 3, 1], device='cuda:3')\n",
      "tensor([2, 0, 1, 2, 0, 2, 0, 2], device='cuda:0')\n",
      "labels_hat tensor([2, 3, 0, 1, 2, 0, 3, 2], device='cuda:0')\n",
      "labels: labels: labels: labels: tensor([3, 3, 2, 0, 2, 2, 3, 3], device='cuda:1')\n",
      "labels_hat tensor([1, 0, 1, 1, 3, 1, 1, 2], device='cuda:2')tensor([0, 0, 2, 2, 2, 1, 3, 2], device='cuda:1')\n",
      "labels_hat \n",
      "tensor([1, 0, 1, 0, 3, 3, 2, 3], device='cuda:2')\n",
      "tensor([2, 3, 3, 0, 0, 3, 0, 3], device='cuda:3')\n",
      "labels_hat tensor([1, 3, 3, 0, 0, 1, 2, 3], device='cuda:3')\n",
      "tensor([3, 0, 2, 1, 0, 0, 2, 2], device='cuda:0')\n",
      "labels_hat tensor([1, 0, 3, 3, 0, 0, 2, 2], device='cuda:0')\n",
      "labels: labels: labels: labels: tensor([0, 3, 3, 1, 0, 0, 0, 2], device='cuda:2')\n",
      "labels_hat tensor([0, 2, 3, 3, 3, 2, 0, 2], device='cuda:2')\n",
      "tensor([0, 2, 2, 1, 0, 0, 2, 3], device='cuda:1')\n",
      "labels_hat tensor([0, 1, 2, 1, 3, 2, 2, 3], device='cuda:1')\n",
      "tensor([3, 3, 3, 1, 2, 0, 1, 3], device='cuda:3')\n",
      "labels_hat tensor([0, 2, 3, 1, 0, 0, 2, 3], device='cuda:3')\n",
      "tensor([1, 2, 3, 1, 1, 1, 3, 1], device='cuda:0')\n",
      "labels_hat tensor([3, 3, 0, 2, 0, 0, 1, 1], device='cuda:0')\n",
      "labels: labels: labels:labels:  tensor([2, 3, 0, 2, 3, 3, 2, 0], device='cuda:1')\n",
      "labels_hat tensor([2, 3, 3, 0, 3, 2, 2, 2], device='cuda:1')\n",
      "tensor([1, 3, 3, 3, 1, 2, 3, 1], device='cuda:2')\n",
      "labels_hat tensor([1, 3, 3, 3, 1, 0, 3, 1], device='cuda:2')\n",
      "tensor([0, 3, 2, 3, 1, 0, 1, 1], device='cuda:3')\n",
      "labels_hat tensor([0, 3, 0, 3, 1, 1, 2, 1], device='cuda:3')\n",
      "tensor([3, 0, 3, 3, 1, 1, 1, 1], device='cuda:0')\n",
      "labels_hat tensor([2, 0, 3, 1, 1, 1, 2, 3], device='cuda:0')\n",
      "labels: labels: labels: labels: tensor([3, 2, 2, 0, 1, 3, 3, 0], device='cuda:1')\n",
      "labels_hat tensor([2, 3, 0, 3, 2, 1, 0, 3], device='cuda:1')\n",
      "tensor([2, 0, 2, 1, 2, 1, 1, 0], device='cuda:2')\n",
      "labels_hat tensor([1, 3, 1, 2, 2, 1, 1, 1], device='cuda:3')tensor([3, 1, 1, 1, 1, 1, 0, 0], device='cuda:2')\n",
      "labels_hat \n",
      "tensor([1, 2, 2, 2, 2, 1, 1, 2], device='cuda:3')\n",
      "tensor([1, 0, 0, 2, 2, 0, 0, 0], device='cuda:0')\n",
      "labels_hat tensor([0, 1, 0, 1, 2, 1, 0, 2], device='cuda:0')\n",
      "labels: labels: labels: labels: tensor([2, 3, 0, 0, 3, 3, 1, 3], device='cuda:1')\n",
      "labels_hat tensor([2, 0, 0, 3, 3, 3, 2, 3], device='cuda:1')\n",
      "tensor([1, 0, 1, 0, 2, 1, 2, 0], device='cuda:2')\n",
      "labels_hat tensor([1, 1, 2, 2, 2, 0, 0, 1], device='cuda:2')\n",
      "tensor([3, 1, 0, 0, 0, 2, 1, 3], device='cuda:3')\n",
      "labels_hat tensor([1, 1, 0, 3, 0, 2, 1, 3], device='cuda:3')\n",
      "tensor([0, 3, 1, 2, 3, 2, 0, 3], device='cuda:0')\n",
      "labels_hat tensor([0, 1, 2, 3, 2, 1, 2, 3], device='cuda:0')\n",
      "labels:labels:  labels: labels: tensor([3, 3, 1, 0, 2, 3, 1, 2], device='cuda:1')\n",
      "labels_hat tensor([3, 1, 1, 1, 0, 3, 1, 2], device='cuda:1')\n",
      "tensor([1, 1, 1, 2, 1, 0, 2, 0], device='cuda:2')\n",
      "labels_hat tensor([1, 1, 1, 1, 1, 3, 3, 0], device='cuda:2')\n",
      "tensor([1, 2, 3, 2, 1, 0, 3, 0], device='cuda:3')\n",
      "labels_hat tensor([2, 0, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "labels_hat tensor([3, 2, 3, 2, 1, 0, 0, 1], device='cuda:3')\n",
      "tensor([2, 1, 3, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "labels: labels: labels: labels: tensor([1, 2, 0, 3, 0, 0, 3, 2], device='cuda:1')\n",
      "labels_hat tensor([0, 1, 2, 0, 3, 1, 0, 1], device='cuda:2')\n",
      "labels_hat tensor([2, 1, 0, 1, 0, 2, 3, 3], device='cuda:1')\n",
      "tensor([0, 1, 2, 0, 0, 1, 0, 1], device='cuda:2')\n",
      "tensor([3, 3, 3, 1, 0, 1, 1, 0], device='cuda:3')\n",
      "labels_hat tensor([1, 1, 2, 1, 1, 0, 2, 2], device='cuda:3')\n",
      "tensor([2, 0, 1, 3, 2, 0, 2, 1], device='cuda:0')\n",
      "labels_hat tensor([1, 0, 1, 3, 2, 3, 2, 1], device='cuda:0')\n",
      "labels: labels: labels: labels: tensor([0, 0, 2, 2, 0, 2, 0, 1], device='cuda:1')tensor([1, 2, 1, 2, 0, 0, 0, 0], device='cuda:2')\n",
      "labels_hat \n",
      "labels_hat tensor([0, 0, 2, 2, 2, 3, 1, 1], device='cuda:1')tensor([3, 2, 1, 2, 0, 0, 0, 2], device='cuda:2')\n",
      "\n",
      "tensor([2, 2, 0, 3, 3, 1, 1, 3], device='cuda:3')\n",
      "labels_hat tensor([0, 2, 0, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "labels_hat tensor([0, 1, 0, 3, 3, 3, 1, 2], device='cuda:3')\n",
      "tensor([1, 3, 2, 2, 2, 1, 0, 2], device='cuda:0')\n",
      "labels: labels: labels: labels: tensor([1, 1, 2, 3, 1, 2, 2, 0], device='cuda:1')\n",
      "labels_hat tensor([2, 2, 2, 2, 1, 0, 1, 1], device='cuda:2')\n",
      "labels_hat tensor([1, 0, 2, 3, 1, 2, 0, 3], device='cuda:1')\n",
      "tensor([3, 2, 1, 0, 3, 1, 0, 2], device='cuda:2')\n",
      "tensor([2, 1, 3, 3, 2, 2, 1, 0], device='cuda:3')\n",
      "labels_hat tensor([2, 1, 0, 3, 2, 0, 1, 1], device='cuda:3')\n",
      "tensor([3, 1, 0, 1, 0, 0, 1, 3], device='cuda:0')\n",
      "labels_hat tensor([3, 1, 1, 0, 3, 3, 1, 0], device='cuda:0')\n",
      "labels: labels: labels: labels: tensor([0, 0, 2, 2, 0], device='cuda:2')\n",
      "labels_hat tensor([1, 3, 1, 2, 0], device='cuda:2')\n",
      "tensor([2, 1, 3, 1, 1], device='cuda:1')\n",
      "labels_hat tensor([0, 1, 3, 1, 2], device='cuda:1')\n",
      "tensor([0, 2, 2, 1, 2], device='cuda:3')\n",
      "labels_hat tensor([3, 0, 3, 1, 2], device='cuda:0')\n",
      "labels_hattensor([0, 2, 3, 1, 0], device='cuda:3')\n",
      " tensor([2, 1, 2, 1, 3], device='cuda:0')\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.20000000298023224, 'test_acc_epoch': 0.4000000059604645}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc_epoch': 0.4000000059604645, 'test_acc': 0.20000000298023224}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use AlbertModel, donot use AlbertforMultiChoice\n",
    "config = AlbertConfig.from_pretrained('albert-base-v2')\n",
    "\n",
    "# # load checkpoint file which you want to use\n",
    "# for path in path_list:\n",
    "#     print('Model in path:' + path)\n",
    "#     checkpoint = torch.load(path)\n",
    "#     new_checkpoint = {}\n",
    "\n",
    "#     for key in checkpoint['state_dict'].keys():\n",
    "#       if 'model' in key:\n",
    "#         new_key = key[6:]\n",
    "#         new_checkpoint[new_key] = checkpoint['state_dict'][key]\n",
    "#       else:\n",
    "#         new_checkpoint[key] = checkpoint['state_dict'][key]\n",
    "        \n",
    "#     m = AlbertForMultipleChoice.from_pretrained(pretrained_model_name_or_path= None, config=config, state_dict=new_checkpoint)\n",
    "#     trainer_for_test = pl.Trainer(gpus=4, accelerator='dp')\n",
    "#     model_for_test = TestModel(m, test_dataloader)\n",
    "#     trainer_for_test.test(model=model_for_test)\n",
    "\n",
    "path = path_list[0]\n",
    "print('Model in path:' + path)\n",
    "checkpoint = torch.load(path)\n",
    "new_checkpoint = {}\n",
    "\n",
    "for key in checkpoint['state_dict'].keys():\n",
    "  if 'model' in key:\n",
    "    new_key = key[6:]\n",
    "    new_checkpoint[new_key] = checkpoint['state_dict'][key]\n",
    "  else:\n",
    "    new_checkpoint[key] = checkpoint['state_dict'][key]\n",
    "\n",
    "m = AlbertForMultipleChoice.from_pretrained(pretrained_model_name_or_path= None, config=config, state_dict=new_checkpoint)\n",
    "trainer_for_test = pl.Trainer(gpus=4, accelerator='dp')\n",
    "model_for_test = TestModel(m, test_dataloader)\n",
    "trainer_for_test.test(model=model_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cognitive-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosmos\tRACE\n",
      "Cosmos\tOpenBook  RACE\n"
     ]
    }
   ],
   "source": [
    "!cd /pfs/work7/workspace/scratch/st_st169719-TQA-0/Chen/ && ls && mkdir OpenBook && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "equipped-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/DR/Ex01/dr_ex01-albert-openbook-epoch=02-val_acc_epoch=0.557.ckpt /pfs/work7/workspace/scratch/st_st169719-TQA-0/Chen/OpenBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eligible-longitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dr_ex01-albert-openbook-epoch=02-val_acc_epoch=0.557.ckpt'\n"
     ]
    }
   ],
   "source": [
    "!cd /pfs/work7/workspace/scratch/st_st169719-TQA-0/Chen/OpenBook/ && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-stamp",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
