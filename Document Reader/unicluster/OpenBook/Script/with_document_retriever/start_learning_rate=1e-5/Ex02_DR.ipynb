{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "shared-budapest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 24 15:20:56 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    40W / 300W |     49MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    42W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    40W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    43W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1784      G   /usr/libexec/Xorg                  48MiB |\n",
      "|    1   N/A  N/A      1784      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    2   N/A  N/A      1784      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    3   N/A  N/A      1784      G   /usr/libexec/Xorg                   8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "common-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd\n",
    "#!cd OpenBook && mkdir dataset\n",
    "#!mkdir third_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polish-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet --target=/pfs/data5/home/st/st_us-051200/st_st169719/third_party pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "international-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wrapped-judges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib64/python3.6/site-packages', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages/IPython/extensions', '/pfs/data5/home/st/st_us-051200/st_st169719/.ipython', '/pfs/data5/home/st/st_us-051200/st_st169719/third_party']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/pfs/data5/home/st/st_us-051200/st_st169719/third_party\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interstate-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from argparse import ArgumentParser\n",
    "import random\n",
    "import numpy as np\n",
    "import json_lines\n",
    "import pickle\n",
    "\n",
    "import lineflow as lf\n",
    "from transformers import AlbertForMultipleChoice, AlbertTokenizer, AdamW\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "other-monthly",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "pl.utilities.seed.seed_everything(seed=0, workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "advanced-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "naval-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "NUM_LABELS = 4\n",
    "label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rotary-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloader_from_cache(cachedir :str):\n",
    "    cachedir = Path(cachedir)\n",
    "\n",
    "    train_file_name = \"cache4_train_ob.cache\"\n",
    "    train_path = Path(cachedir / train_file_name)\n",
    "    if train_path.exists():\n",
    "        print(f'Loading data from {train_file_name}...')\n",
    "        with train_path.open('rb') as f:\n",
    "            train_cache = pickle.load(f)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(train_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=40\n",
    "            )\n",
    "\n",
    "    val_file_name = \"cache4_dev_ob.cache\"\n",
    "    val_path = Path(cachedir / val_file_name)\n",
    "    if val_path.exists():\n",
    "        print(f'Loading data from {val_file_name}...')\n",
    "        with val_path.open('rb') as f:\n",
    "            val_cache = pickle.load(f)\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(val_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=40\n",
    "            )\n",
    "    \n",
    "    test_file_name = \"cache4_test_ob.cache\"\n",
    "    test_path = Path(cachedir / test_file_name)\n",
    "    if test_path.exists():\n",
    "        print(f'Loading data from {val_file_name}...')\n",
    "        with test_path.open('rb') as f:\n",
    "            test_cache = pickle.load(f)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(test_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=40\n",
    "            )\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "quality-cliff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from cache4_train_ob.cache...\n",
      "Loading data from cache4_dev_ob.cache...\n",
      "Loading data from cache4_dev_ob.cache...\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = load_dataloader_from_cache('../../../Philippe/Caches_New/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reflected-island",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "choice-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.metrics import functional as FM\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adjusted-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertConfig\n",
    "config = AlbertConfig.from_pretrained('albert-base-v2')\n",
    "\n",
    "path = '../../Checkpoints/DR1e-5/Ex01/dr_ex01-albert-openbook-epoch=02-val_loss_epoch=1.220.ckpt'\n",
    "\n",
    "checkpoint = torch.load(path)\n",
    "new_checkpoint = {}\n",
    "\n",
    "for key in checkpoint['state_dict'].keys():\n",
    "  if 'model' in key:\n",
    "    new_key = key[6:]\n",
    "    new_checkpoint[new_key] = checkpoint['state_dict'][key]\n",
    "  else:\n",
    "    new_checkpoint[key] = checkpoint['state_dict'][key]\n",
    "\n",
    "m = AlbertForMultipleChoice.from_pretrained(pretrained_model_name_or_path= None, config=config, state_dict=new_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "listed-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        #model = AlbertForMultipleChoice.from_pretrained(\"albert-base-v2\", num_labels=NUM_LABELS)\n",
    "        self.model = model\n",
    "\n",
    "        self._train_dataloader = train_dataloader\n",
    "        self._val_dataloader = val_dataloader\n",
    "        self._test_dataloader = test_dataloader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        weight_decay = 0.0\n",
    "        adam_epsilon = 1e-8\n",
    "\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': weight_decay\n",
    "                },\n",
    "            {\n",
    "                'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.0,\n",
    "                }\n",
    "            ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, eps=adam_epsilon)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        # print(labels.size())\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "\n",
    "        self.log('train_loss', outputs.loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return outputs.loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "\n",
    "        self.log('val_loss', outputs.loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log('val_acc', acc, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "                \n",
    "        return acc\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        acc = self.validation_step(batch, batch_idx)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self._train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._val_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "recovered-tenant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# saves a file like: my/path/albert-openbook-epoch=02-val_loss_epoch=0.32.ckpt\n",
    "# if you don't want to save checkpoint into google drive, change dirpath!!!\n",
    "loss_checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss_epoch',\n",
    "    dirpath='../../Checkpoints/DR1e-5/Ex02',\n",
    "    # dirpath='/your/path/',\n",
    "    filename='dr_ex02-albert-openbook-{epoch:02d}-{val_loss_epoch:.3f}',\n",
    "    save_top_k=2,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "acc_checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc_epoch',\n",
    "    dirpath='../../Checkpoints/DR1e-5/Ex02',\n",
    "    # dirpath='/your/path/',\n",
    "    filename='dr_ex02-albert-openbook-{epoch:02d}-{val_acc_epoch:.3f}',\n",
    "    save_top_k=2,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(gpus=4, max_epochs=5, callbacks=[loss_checkpoint_callback, acc_checkpoint_callback], accelerator='dp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bacterial-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_model = Model(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stock-intake",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | AlbertForMultipleChoice | 11.7 M\n",
      "--------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.737    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798c9ccd315044339c6b7f91c900f47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "returning-memorabilia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce37f950e67433a88a3720381fe758a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.20000000298023224,\n",
      " 'test_acc_epoch': 0.37756410241127014,\n",
      " 'val_acc': 0.20000000298023224,\n",
      " 'val_acc_epoch': 0.37756410241127014,\n",
      " 'val_loss': 1.3196347951889038,\n",
      " 'val_loss_epoch': 1.4501855373382568}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = trainer.test(test_dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tested-lesbian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/DR5e-6/Ex02/dr_ex02-albert-openbook-epoch=00-val_acc_epoch=0.399.ckpt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "concrete-carrier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/DR5e-6/Ex02/dr_ex02-albert-openbook-epoch=00-val_loss_epoch=1.478.ckpt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dried-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./lightning_logs ../../Checkpoints/DR5e-6/Ex02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-bargain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-bullet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
