{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floppy-bishop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 12 09:41:33 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    43W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    42W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    42W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    39W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    1   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    2   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    3   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entertaining-tours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/st/st_us-051200/st_st169719\n",
      "mkdir: cannot create directory ‘dataset’: File exists\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!cd OpenBook && mkdir dataset\n",
    "!mkdir third_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-philosophy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "royal-monte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Target directory /pfs/data5/home/st/st_us-051200/st_st169719/third_party/google already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --target=/pfs/data5/home/st/st_us-051200/st_st169719/third_party pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "jewish-tissue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: protobuf in ./.local/lib/python3.6/site-packages (3.17.3)\n",
      "Requirement already satisfied: six>=1.9 in /pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib/python3.6/site-packages (from protobuf) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "native-transition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib64/python3.6/site-packages', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages/IPython/extensions', '/pfs/data5/home/st/st_us-051200/st_st169719/.ipython', '/pfs/data5/home/st/st_us-051200/st_st169719/third_party']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/pfs/data5/home/st/st_us-051200/st_st169719/third_party\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "south-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import lineflow as lf\n",
    "from transformers import AlbertForMultipleChoice, AlbertTokenizer, AdamW\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "import json_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mechanical-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "closed-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compliant-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "NUM_LABELS = 4\n",
    "label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unusual-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_samples_to_dataset(samples):\n",
    "    datas = []\n",
    "    for sample in samples:\n",
    "        _id = sample[\"id\"]\n",
    "        _article = sample[\"fact1\"]\n",
    "        _question = sample[\"question\"]['stem']\n",
    "        _options = []\n",
    "        _answer = sample[\"answerKey\"]\n",
    "        for idx in range(len(sample['question']['choices'])): \n",
    "            _options.append(sample[\"question\"]['choices'][idx]['text'])\n",
    "\n",
    "        data = {\n",
    "                \"id\": _id,\n",
    "                \"article\": _article,\n",
    "                \"options\": _options,\n",
    "                \"question\": _question,\n",
    "                \"answer\": _answer\n",
    "                }\n",
    "        datas.append(data)\n",
    "    return lf.Dataset(datas)\n",
    "\n",
    "\n",
    "def preprocess(tokenizer: AlbertTokenizer, x: Dict) -> Dict:\n",
    "\n",
    "    choices_features = []\n",
    "\n",
    "    option: str\n",
    "    for option in x[\"options\"]:\n",
    "        text_a = x[\"article\"]\n",
    "        text_b = x[\"question\"] + \" \" + option\n",
    "\n",
    "        inputs = tokenizer.encode_plus(\n",
    "                text_a,\n",
    "                text_b,\n",
    "                add_special_tokens=True,\n",
    "                max_length=MAX_LEN\n",
    "                )\n",
    "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        pad_token_id = tokenizer.pad_token_id\n",
    "        padding_length = MAX_LEN - len(input_ids)\n",
    "        input_ids = input_ids + ([pad_token_id] * padding_length)\n",
    "        attention_mask = attention_mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([pad_token_id] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(input_ids), MAX_LEN)\n",
    "        assert len(attention_mask) == MAX_LEN, \"Error with input length {} vs {}\".format(len(attention_mask), MAX_LEN)\n",
    "        assert len(token_type_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(token_type_ids), MAX_LEN)\n",
    "\n",
    "        choices_features.append({\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"token_type_ids\": token_type_ids,\n",
    "            })\n",
    "\n",
    "    labels = label_map.get(x[\"answer\"], -1)\n",
    "    label = torch.tensor(labels).long()\n",
    "\n",
    "    return {\n",
    "            \"id\": x[\"id\"],\n",
    "            \"label\": label,\n",
    "            \"input_ids\": torch.tensor([cf[\"input_ids\"] for cf in choices_features]),\n",
    "            \"attention_mask\": torch.tensor([cf[\"attention_mask\"] for cf in choices_features]),\n",
    "            \"token_type_ids\": torch.tensor([cf[\"token_type_ids\"] for cf in choices_features]),\n",
    "            }\n",
    "\n",
    "\n",
    "def get_dataloader(tokenizer, datadir: str, cachedir: str = \"./\"):\n",
    "    datadir = Path(datadir)\n",
    "    cachedir = Path(cachedir)\n",
    "    \n",
    "\n",
    "    preprocessor = partial(preprocess, tokenizer)\n",
    "\n",
    "    train_samples = []\n",
    "    with open(datadir / \"train_complete.jsonl\") as f:\n",
    "        for item in json_lines.reader(f):\n",
    "            train_samples.append(item)\n",
    "    train = raw_samples_to_dataset(train_samples)\n",
    "    print(train)\n",
    "    train_dataloader = DataLoader(\n",
    "            train.map(preprocessor).save(cachedir / \"train_openbook.cache\"),\n",
    "            sampler=RandomSampler(train),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=80\n",
    "            )\n",
    "\n",
    "    val_samples = []\n",
    "    with open(datadir / \"dev_complete.jsonl\") as f:\n",
    "        for item in json_lines.reader(f):\n",
    "            val_samples.append(item)\n",
    "    val = raw_samples_to_dataset(val_samples)\n",
    "    val_dataloader = DataLoader(\n",
    "            val.map(preprocessor).save(cachedir / \"val_openbook.cache\"),\n",
    "            sampler=SequentialSampler(val),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=80\n",
    "            )\n",
    "\n",
    "    \n",
    "    test_samples = []\n",
    "    with open(datadir / \"test_complete.jsonl\") as f:\n",
    "        for item in json_lines.reader(f):\n",
    "            test_samples.append(item)\n",
    "    test = raw_samples_to_dataset(test_samples)\n",
    "    test_dataloader = DataLoader(\n",
    "            test.map(preprocessor).save(cachedir / \"test_openbook.cache\"),\n",
    "            sampler=SequentialSampler(test),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=80\n",
    "            )\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bearing-segment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyterhub_slurmspawner_19586215.log  OpenBook\n",
      "jupyterhub_slurmspawner_19586262.log  third_party\n",
      "--2021-06-11 23:33:36--  https://ai2-public-datasets.s3.amazonaws.com/open-book-qa/OpenBookQA-V1-Sep2018.zip\n",
      "Resolving ai2-public-datasets.s3.amazonaws.com (ai2-public-datasets.s3.amazonaws.com)... 52.218.153.75\n",
      "Connecting to ai2-public-datasets.s3.amazonaws.com (ai2-public-datasets.s3.amazonaws.com)|52.218.153.75|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1446098 (1.4M) [binary/octet-stream]\n",
      "Saving to: ‘OpenBookQA-V1-Sep2018.zip’\n",
      "\n",
      "OpenBookQA-V1-Sep20 100%[===================>]   1.38M  1.35MB/s    in 1.0s    \n",
      "\n",
      "2021-06-11 23:33:38 (1.35 MB/s) - ‘OpenBookQA-V1-Sep2018.zip’ saved [1446098/1446098]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ls \n",
    "!cd OpenBook/dataset && wget https://ai2-public-datasets.s3.amazonaws.com/open-book-qa/OpenBookQA-V1-Sep2018.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eligible-turtle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  OpenBookQA-V1-Sep2018.zip\n",
      "   creating: OpenBookQA-V1-Sep2018/\n",
      "   creating: OpenBookQA-V1-Sep2018/Data/\n",
      "   creating: OpenBookQA-V1-Sep2018/Data/Additional/\n",
      "  inflating: OpenBookQA-V1-Sep2018/Data/Additional/test_complete.jsonl  \n",
      "  inflating: OpenBookQA-V1-Sep2018/Data/Additional/train_complete.jsonl  \n",
      "  inflating: OpenBookQA-V1-Sep2018/Data/Additional/crowdsourced-facts.txt  \n",
      "  inflating: OpenBookQA-V1-Sep2018/Data/Additional/dev_complete.jsonl  \n",
      "   creating: OpenBookQA-V1-Sep2018/Data/Main/\n",
      "  inflating: OpenBookQA-V1-Sep2018/Data/Main/train.jsonl  \n",
      "  inflating: OpenBookQA-V1-Sep2018/Data/Main/test.jsonl  \n",
      "  inflating: OpenBookQA-V1-Sep2018/Data/Main/train.tsv  \n",
      "  inflating: OpenBookQA-V1-Sep2018/Data/Main/dev.tsv  \n",
      "  inflating: OpenBookQA-V1-Sep2018/Data/Main/dev.jsonl  \n",
      "  inflating: OpenBookQA-V1-Sep2018/Data/Main/openbook.txt  \n",
      "  inflating: OpenBookQA-V1-Sep2018/Data/Main/test.tsv  \n",
      "OpenBookQA-V1-Sep2018  OpenBookQA-V1-Sep2018.zip\n"
     ]
    }
   ],
   "source": [
    "!cd OpenBook/dataset && unzip OpenBookQA-V1-Sep2018.zip && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "distributed-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crowdsourced-facts.txt\ttest_complete.jsonl\n",
      "dev_complete.jsonl\ttrain_complete.jsonl\n",
      "/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/dataset/OpenBookQA-V1-Sep2018/Data/Additional\n"
     ]
    }
   ],
   "source": [
    "!cd OpenBook/dataset/OpenBookQA-V1-Sep2018/Data/Additional && ls && pwd\n",
    "!cd OpenBook/dataset && mkdir CacheFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "desperate-concrete",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Script\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outdoor-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/OpenBook/dataset/CacheFiles && mkdir BatchSize64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "classified-investigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lineflow.core.Dataset object at 0x152fe4326dd8>\n",
      "Loading data from /pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/dataset/CacheFiles/BatchSize32/train_openbook.cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 80 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/dataset/CacheFiles/BatchSize32/val_openbook.cache...\n",
      "Loading data from /pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/dataset/CacheFiles/BatchSize32/test_openbook.cache...\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\", do_lower_case=True)\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloader(tokenizer, '/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/dataset/OpenBookQA-V1-Sep2018/Data/Additional', \n",
    "                                                                   '/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/dataset/CacheFiles/BatchSize32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "smart-overhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "strange-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.metrics import functional as FM\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "practical-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        model = AlbertForMultipleChoice.from_pretrained(\"albert-base-v2\", num_labels=NUM_LABELS)\n",
    "        self.model = model\n",
    "\n",
    "        self._train_dataloader = train_dataloader\n",
    "        self._val_dataloader = val_dataloader\n",
    "        self._test_dataloader = test_dataloader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        weight_decay = 0.0\n",
    "        adam_epsilon = 1e-8\n",
    "\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': weight_decay\n",
    "                },\n",
    "            {\n",
    "                'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.0,\n",
    "                }\n",
    "            ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, eps=adam_epsilon)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        # print(labels.size())\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "\n",
    "        self.log('train_loss', outputs.loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return outputs.loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "\n",
    "        self.log('val_loss', outputs.loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log('val_acc', acc, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "                \n",
    "        return acc\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        acc = self.validation_step(batch, batch_idx)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self._train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._val_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daily-mauritius",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# saves a file like: my/path/albert-openbook-epoch=02-val_loss_epoch=0.32.ckpt\n",
    "# if you don't want to save checkpoint into google drive, change dirpath!!!\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss_epoch',\n",
    "    dirpath='/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex03',\n",
    "    # dirpath='/your/path/',\n",
    "    filename='ex03-albert-openbook-{epoch:02d}-{val_loss_epoch:.2f}',\n",
    "    save_top_k=2,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(gpus=4, max_epochs=10, callbacks=[checkpoint_callback], accelerator='dp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "arctic-airplane",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForMultipleChoice: ['predictions.decoder.bias', 'predictions.decoder.weight', 'predictions.dense.weight', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForMultipleChoice were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pl_model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adult-final",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | AlbertForMultipleChoice | 11.7 M\n",
      "--------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.737    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f785e2f5f4dc47539595bcdc3c2e0779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aware-permission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex03/ex03-albert-openbook-epoch=06-val_loss_epoch=1.08.ckpt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "failing-pencil",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb95db33786b41979dbd07429ef01873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.4000000059604645,\n",
      " 'test_acc_epoch': 0.38333332538604736,\n",
      " 'val_acc': 0.4000000059604645,\n",
      " 'val_acc_epoch': 0.38333332538604736,\n",
      " 'val_loss': 1.054306983947754,\n",
      " 'val_loss_epoch': 1.262165904045105}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = trainer.test(test_dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "engaged-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -R ./lightning_logs /pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "effective-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-screw",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
