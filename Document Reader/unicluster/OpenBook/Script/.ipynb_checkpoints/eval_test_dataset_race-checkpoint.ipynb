{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "flying-auckland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib64/python3.6/site-packages', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages/IPython/extensions', '/pfs/data5/home/st/st_us-051200/st_st169719/.ipython', '/pfs/data5/home/st/st_us-051200/st_st169719/third_party']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/pfs/data5/home/st/st_us-051200/st_st169719/third_party\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dominican-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import lineflow as lf\n",
    "from transformers import AlbertForMultipleChoice, AlbertTokenizer, AdamW\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "import json_lines\n",
    "from transformers import AlbertConfig\n",
    "import pickle\n",
    "from pytorch_lightning.metrics import functional as FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acute-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed seed\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polyphonic-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed seed for generating dataset\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "considerable-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "neutral-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloader_from_cache(cachedir :str):\n",
    "    cachedir = Path(cachedir)\n",
    "\n",
    "    train_file_name = \"train_openbook.cache\"\n",
    "    train_path = Path(cachedir / train_file_name)\n",
    "    if train_path.exists():\n",
    "        print(f'Loading data from {train_file_name}...')\n",
    "        with train_path.open('rb') as f:\n",
    "            train_cache = pickle.load(f)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(train_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,#new here, used for fixed seed when generating dataloader\n",
    "            num_workers=80 # new here, 80 is chosen when using 4 gpus in unicluster\n",
    "            )\n",
    "\n",
    "    val_file_name = \"val_openbook.cache\"\n",
    "    val_path = Path(cachedir / val_file_name)\n",
    "    if val_path.exists():\n",
    "        print(f'Loading data from {val_file_name}...')\n",
    "        with val_path.open('rb') as f:\n",
    "            val_cache = pickle.load(f)\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(val_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,#new here, used for fixed seed when generating dataloader\n",
    "            num_workers=80 # new here, 80 is chosen when using 4 gpus in unicluster\n",
    "            )\n",
    "\n",
    "    \n",
    "    test_file_name = \"test_openbook.cache\"\n",
    "    test_path = Path(cachedir / test_file_name)\n",
    "    if test_path.exists():\n",
    "        print(f'Loading data from {test_file_name}...')\n",
    "        with test_path.open('rb') as f:\n",
    "            test_cache = pickle.load(f)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(test_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,#new here, used for fixed seed when generating dataloader\n",
    "            num_workers=80 # new here, 80 is chosen when using 4 gpus in unicluster\n",
    "            )\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "outside-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, test_dataloader):\n",
    "        super(TestModel, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self._test_dataloader = test_dataloader\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pharmaceutical-characterization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from train_openbook.cache...\n",
      "Loading data from val_openbook.cache...\n",
      "Loading data from test_openbook.cache...\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = load_dataloader_from_cache('/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/dataset/CacheFiles/BatchSize32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rotary-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = '/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex01/ex01-albert-openbook-epoch=01-val_loss_epoch=0.76.ckpt'\n",
    "path_2 = '/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex01/ex01-albert-openbook-epoch=02-val_loss_epoch=0.78.ckpt'\n",
    "path_3 = '/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex02/ex02-albert-openbook-epoch=04-val_loss_epoch=1.05.ckpt'\n",
    "path_4 = '/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex02/ex02-albert-openbook-epoch=05-val_loss_epoch=1.07.ckpt'\n",
    "path_5 = '/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex03/ex03-albert-openbook-epoch=05-val_loss_epoch=1.08.ckpt'\n",
    "path_6 = '/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex03/ex03-albert-openbook-epoch=06-val_loss_epoch=1.08.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "stainless-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = []\n",
    "path_list.append(path_1)\n",
    "path_list.append(path_2)\n",
    "path_list.append(path_3)\n",
    "path_list.append(path_4)\n",
    "path_list.append(path_5)\n",
    "path_list.append(path_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "experienced-indonesian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex01/ex01-albert-openbook-epoch=01-val_loss_epoch=0.76.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24a8c925ef94a6ba2fa5850195a3c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.800000011920929, 'test_acc_epoch': 0.656089723110199}\n",
      "--------------------------------------------------------------------------------\n",
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex01/ex01-albert-openbook-epoch=02-val_loss_epoch=0.78.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eab2465b073477a99fc2f68da282fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.6000000238418579, 'test_acc_epoch': 0.6407051086425781}\n",
      "--------------------------------------------------------------------------------\n",
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex02/ex02-albert-openbook-epoch=04-val_loss_epoch=1.05.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0e91e075cb4db88196cb0a69a9b51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.4000000059604645, 'test_acc_epoch': 0.617307722568512}\n",
      "--------------------------------------------------------------------------------\n",
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex02/ex02-albert-openbook-epoch=05-val_loss_epoch=1.07.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a645b3d003419e880c78b2d5f1ed15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.4000000059604645, 'test_acc_epoch': 0.612500011920929}\n",
      "--------------------------------------------------------------------------------\n",
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex03/ex03-albert-openbook-epoch=05-val_loss_epoch=1.08.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b088d4359b9426c9a4e0be846181237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.4000000059604645, 'test_acc_epoch': 0.4971154034137726}\n",
      "--------------------------------------------------------------------------------\n",
      "Model in path:/pfs/data5/home/st/st_us-051200/st_st169719/OpenBook/Checkpoints/Ex03/ex03-albert-openbook-epoch=06-val_loss_epoch=1.08.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c903e720a1442b2ba4a83adb767ab97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.4000000059604645, 'test_acc_epoch': 0.48750001192092896}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# use AlbertModel, donot use AlbertforMultiChoice\n",
    "config = AlbertConfig.from_pretrained('albert-base-v2')\n",
    "\n",
    "# load checkpoint file which you want to use\n",
    "for path in path_list:\n",
    "    print('Model in path:' + path)\n",
    "    checkpoint = torch.load(path)\n",
    "    new_checkpoint = {}\n",
    "\n",
    "    for key in checkpoint['state_dict'].keys():\n",
    "      if 'model' in key:\n",
    "        new_key = key[6:]\n",
    "        new_checkpoint[new_key] = checkpoint['state_dict'][key]\n",
    "      else:\n",
    "        new_checkpoint[key] = checkpoint['state_dict'][key]\n",
    "        \n",
    "    m = AlbertForMultipleChoice.from_pretrained(pretrained_model_name_or_path= None, config=config, state_dict=new_checkpoint)\n",
    "    trainer_for_test = pl.Trainer(gpus=4, accelerator='dp')\n",
    "    model_for_test = TestModel(m, test_dataloader)\n",
    "    trainer_for_test.test(model=model_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-mission",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
