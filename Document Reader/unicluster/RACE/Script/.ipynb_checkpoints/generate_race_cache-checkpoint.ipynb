{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "residential-demonstration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 12 10:23:58 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    44W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    42W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    42W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    39W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    1   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    2   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    3   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southern-corruption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib64/python3.6/site-packages', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages/IPython/extensions', '/pfs/data5/home/st/st_us-051200/st_st169719/.ipython', '/pfs/data5/home/st/st_us-051200/st_st169719/third_party']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/pfs/data5/home/st/st_us-051200/st_st169719/third_party\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intense-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import lineflow as lf\n",
    "from transformers import AlbertForMultipleChoice, AlbertTokenizer, AdamW\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "import json_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "official-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ongoing-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "arctic-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "NUM_LABELS = 4\n",
    "label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_samples_to_dataset(samples):\n",
    "    datas = []\n",
    "    i = 0\n",
    "    for sample in samples:\n",
    "      i = i + 1\n",
    "      if i% 1000 == 0:\n",
    "        print(i)\n",
    "      for idx in range(len(sample[\"answers\"])):\n",
    "          _id = sample[\"id\"]\n",
    "          _article = sample[\"article\"]\n",
    "          _answer = sample[\"answers\"][idx]\n",
    "          _options = sample[\"options\"][idx]\n",
    "          _question = sample[\"questions\"][idx]\n",
    "\n",
    "          data = {\n",
    "                  \"id\": _id,\n",
    "                  \"article\": _article,\n",
    "                  \"answer\": _answer,\n",
    "                  \"options\": _options,\n",
    "                  \"question\": _question,\n",
    "                  }\n",
    "          datas.append(data)\n",
    "            \n",
    "    return lf.Dataset(datas)\n",
    "\n",
    "\n",
    "def preprocess(tokenizer: AlbertTokenizer, x: Dict) -> Dict:\n",
    "\n",
    "    choices_features = []\n",
    "\n",
    "    option: str\n",
    "    for option in x[\"options\"]:\n",
    "        text_a = x[\"article\"]\n",
    "        if x[\"question\"].find(\"_\") != -1:\n",
    "            text_b = x[\"question\"].replace(\"_\", option)\n",
    "        else:\n",
    "            text_b = x[\"question\"] + \" \" + option\n",
    "\n",
    "        inputs = tokenizer.encode_plus(\n",
    "                text_a,\n",
    "                text_b,\n",
    "                add_special_tokens=True,\n",
    "                max_length=MAX_LEN\n",
    "                )\n",
    "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        pad_token_id = tokenizer.pad_token_id\n",
    "        padding_length = MAX_LEN - len(input_ids)\n",
    "        input_ids = input_ids + ([pad_token_id] * padding_length)\n",
    "        attention_mask = attention_mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([pad_token_id] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(input_ids), MAX_LEN)\n",
    "        assert len(attention_mask) == MAX_LEN, \"Error with input length {} vs {}\".format(len(attention_mask), MAX_LEN)\n",
    "        assert len(token_type_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(token_type_ids), MAX_LEN)\n",
    "\n",
    "        choices_features.append({\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"token_type_ids\": token_type_ids,\n",
    "            })\n",
    "\n",
    "    labels = label_map.get(x[\"answer\"], -1)\n",
    "    label = torch.tensor(labels).long()\n",
    "\n",
    "    return {\n",
    "            \"id\": x[\"id\"],\n",
    "            \"label\": label,\n",
    "            \"input_ids\": torch.tensor([cf[\"input_ids\"] for cf in choices_features]),\n",
    "            \"attention_mask\": torch.tensor([cf[\"attention_mask\"] for cf in choices_features]),\n",
    "            \"token_type_ids\": torch.tensor([cf[\"token_type_ids\"] for cf in choices_features]),\n",
    "            }\n",
    "\n",
    "\n",
    "def get_dataloader(tokenizer, datadir: str, cachedir: str = \"./\"):\n",
    "    datadir = Path(datadir)\n",
    "    cachedir = Path(cachedir)\n",
    "  \n",
    "    preprocessor = partial(preprocess, tokenizer)\n",
    "\n",
    "    train_samples = []\n",
    "    for grade in (\"middle\", \"high\"):\n",
    "        for _path in (datadir / \"train\" / grade).iterdir():\n",
    "            train_samples.append(json.loads(_path.read_text()))\n",
    "    train = raw_samples_to_dataset(train_samples)\n",
    "    train_dataloader = DataLoader(\n",
    "            train.map(preprocessor).save(cachedir / \"train_race_256.cache\"),\n",
    "            sampler=RandomSampler(train),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=80\n",
    "            )\n",
    "\n",
    "    val_samples = []\n",
    "    for grade in (\"middle\", \"high\"):\n",
    "        for _path in (datadir / \"dev\" / grade).iterdir():\n",
    "            val_samples.append(json.loads(_path.read_text()))\n",
    "    val = raw_samples_to_dataset(val_samples)\n",
    "    val_dataloader = DataLoader(\n",
    "            val.map(preprocessor).save(cachedir / \"val_race_256.cache\"),\n",
    "            sampler=SequentialSampler(val),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=80\n",
    "            )\n",
    "\n",
    "    test_samples = []\n",
    "    for grade in (\"middle\", \"high\"):\n",
    "        for _path in (datadir / \"test\" / grade).iterdir():\n",
    "            test_samples.append(json.loads(_path.read_text()))\n",
    "    test = raw_samples_to_dataset(test_samples)\n",
    "    test_dataloader = DataLoader(\n",
    "            test.map(preprocessor).save(cachedir / \"test_race_256.cache\"),\n",
    "            sampler=SequentialSampler(test),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=80\n",
    "            )\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
