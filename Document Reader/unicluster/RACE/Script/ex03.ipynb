{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "martial-listing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib64/python3.6/site-packages', '/pfs/data5/software_uc2/bwhpc/common/jupyter/base/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', '/opt/bwhpc/common/jupyter/base/lib/python3.6/site-packages/IPython/extensions', '/pfs/data5/home/st/st_us-051200/st_st169719/.ipython', '/pfs/data5/home/st/st_us-051200/st_st169719/third_party']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/pfs/data5/home/st/st_us-051200/st_st169719/third_party\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "owned-stocks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 12 20:30:15 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:16:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    46W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    44W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    42W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    43W / 300W |      9MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    1   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    2   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    3   N/A  N/A      1888      G   /usr/libexec/Xorg                   8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "skilled-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import lineflow as lf\n",
    "from transformers import AlbertForMultipleChoice, AlbertTokenizer, AdamW\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "import json_lines\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greater-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "similar-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "supposed-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "NUM_LABELS = 4\n",
    "label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "earlier-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloader_from_cache(cachedir :str):\n",
    "    cachedir = Path(cachedir)\n",
    "\n",
    "    train_file_name = \"train_race.cache\"\n",
    "    train_path = Path(cachedir / train_file_name)\n",
    "    if train_path.exists():\n",
    "        print(f'Loading data from {train_file_name}...')\n",
    "        with train_path.open('rb') as f:\n",
    "            train_cache = pickle.load(f)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(train_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=80\n",
    "            )\n",
    "\n",
    "    val_file_name = \"val_race.cache\"\n",
    "    val_path = Path(cachedir / val_file_name)\n",
    "    if val_path.exists():\n",
    "        print(f'Loading data from {val_file_name}...')\n",
    "        with val_path.open('rb') as f:\n",
    "            val_cache = pickle.load(f)\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(val_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=80\n",
    "            )\n",
    "\n",
    "    \n",
    "    test_file_name = \"test_race.cache\"\n",
    "    test_path = Path(cachedir / test_file_name)\n",
    "    if test_path.exists():\n",
    "        print(f'Loading data from {test_file_name}...')\n",
    "        with test_path.open('rb') as f:\n",
    "            test_cache = pickle.load(f)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "            lf.core.CacheDataset(test_cache),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            worker_init_fn=seed_worker,\n",
    "            num_workers=80\n",
    "            )\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "threatened-daniel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from train_race.cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/st/st_us-051200/st_st169719/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 80 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from val_race.cache...\n",
      "Loading data from test_race.cache...\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = load_dataloader_from_cache('/pfs/data5/home/st/st_us-051200/st_st169719/RACE/dataset/CacheFiles/BatchSize32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "handed-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/pfs/data5/home/st/st_us-051200/st_st169719/RACE/Checkpoints/Ex02/e2-albert-race-epoch=00-val_loss_epoch=0.77.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "republican-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_checkpoint = {}\n",
    "\n",
    "for key in checkpoint['state_dict'].keys():\n",
    "  if 'model' in key:\n",
    "    new_key = key[6:]\n",
    "    new_checkpoint[new_key] = checkpoint['state_dict'][key]\n",
    "  else:\n",
    "    new_checkpoint[key] = checkpoint['state_dict'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acting-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertConfig\n",
    "config = AlbertConfig.from_pretrained('albert-base-v2')\n",
    "m = AlbertForMultipleChoice.from_pretrained(pretrained_model_name_or_path= None, config=config, state_dict=new_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "further-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.metrics import functional as FM\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "typical-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "#         model = AlbertForMultipleChoice.from_pretrained(\"albert-base-v2\", num_labels=NUM_LABELS)\n",
    "        self.model = model\n",
    "\n",
    "        self._train_dataloader = train_dataloader\n",
    "        self._val_dataloader = val_dataloader\n",
    "        self._test_dataloader = test_dataloader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        weight_decay = 0.0\n",
    "        adam_epsilon = 1e-8\n",
    "\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': weight_decay\n",
    "                },\n",
    "            {\n",
    "                'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.0,\n",
    "                }\n",
    "            ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, eps=adam_epsilon)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        # print(labels.size())\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "\n",
    "        self.log('train_loss', outputs.loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return outputs.loss\n",
    "  \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "\n",
    "        self.log('val_loss', outputs.loss, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log('val_acc', acc, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "                \n",
    "        return acc\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        acc = self.validation_step(batch, batch_idx)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self._train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._val_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sound-position",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# saves a file like: my/path/albert-openbook-epoch=02-val_loss_epoch=0.32.ckpt\n",
    "# if you don't want to save checkpoint into google drive, change dirpath!!!\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss_epoch',\n",
    "    dirpath='/pfs/data5/home/st/st_us-051200/st_st169719/RACE/Checkpoints/Ex03',\n",
    "    # dirpath='/your/path/',\n",
    "    filename='e3-albert-race-{epoch:02d}-{val_loss_epoch:.2f}',\n",
    "    save_top_k=2,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(gpus=4, max_epochs=2, callbacks=[checkpoint_callback], accelerator='dp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "theoretical-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_model = Model(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "normal-italic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | AlbertForMultipleChoice | 11.7 M\n",
      "--------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.737    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a4d3f3484c4b75b47c7afda86fd59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adequate-selling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/pfs/data5/home/st/st_us-051200/st_st169719/RACE/Checkpoints/Ex03/e3-albert-race-epoch=00-val_loss_epoch=0.97.ckpt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dominican-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/pfs/data5/home/st/st_us-051200/st_st169719/RACE/Checkpoints/Ex03/e3-albert-race-epoch=00-val_loss_epoch=0.97.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "assisted-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_checkpoint = {}\n",
    "\n",
    "for key in checkpoint['state_dict'].keys():\n",
    "  if 'model' in key:\n",
    "    new_key = key[6:]\n",
    "    new_checkpoint[new_key] = checkpoint['state_dict'][key]\n",
    "  else:\n",
    "    new_checkpoint[key] = checkpoint['state_dict'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "private-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertConfig\n",
    "config = AlbertConfig.from_pretrained('albert-base-v2')\n",
    "m_new = AlbertForMultipleChoice.from_pretrained(pretrained_model_name_or_path= None, config=config, state_dict=new_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sustainable-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, test_dataloader):\n",
    "        super(TestModel, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self._test_dataloader = test_dataloader\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        labels = batch[\"label\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "\n",
    "        outputs = self.model(\n",
    "                input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "                )\n",
    "        \n",
    "        labels_hat = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        acc = FM.accuracy(labels_hat, labels)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afraid-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2a0ea6b14f4b3e9e3f36e1b79681d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 1.0, 'test_acc_epoch': 0.7009925842285156}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc_epoch': 0.7009925842285156, 'test_acc': 1.0}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_for_test = pl.Trainer(gpus=4, accelerator='dp')\n",
    "model_for_test = TestModel(m_new, test_dataloader)\n",
    "trainer_for_test.test(model=model_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -R ./lightning_logs /pfs/data5/home/st/st_us-051200/st_st169719/RACE/Checkpoints/Ex03"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
