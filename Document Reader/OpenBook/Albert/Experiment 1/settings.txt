MAX_LEN = 64
NUM_LABELS = 4
label_map = {"A": 0, "B": 1, "C": 2, "D": 3}
BATCH_SIZE = 8

no_decay = ['bias', 'LayerNorm.weight']
weight_decay = 0.0
adam_epsilon = 1e-8

optimizer_grouped_parameters = [
{
    'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],
    'weight_decay': weight_decay
    },
{
    'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],
    'weight_decay': 0.0,
    }
]
optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=adam_epsilon)
