{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuningRace.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "094ca1acabff4fa9bebf66d30b892b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_757c4f1b645a47f287cef92eeb2dbf0e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6b07a54eaacf4efaaf79144c5b7c8bc8",
              "IPY_MODEL_696a17218952435db2c10047a277a28d"
            ]
          }
        },
        "757c4f1b645a47f287cef92eeb2dbf0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b07a54eaacf4efaaf79144c5b7c8bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_49813d5246b143ca88937af6708cf02f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_860260ca4af043199432297156fac085"
          }
        },
        "696a17218952435db2c10047a277a28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ebd0a509636546d79e3ac7cf4f87c6a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 2.71kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2204240fd234160a9e8814cf4c69137"
          }
        },
        "49813d5246b143ca88937af6708cf02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "860260ca4af043199432297156fac085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebd0a509636546d79e3ac7cf4f87c6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2204240fd234160a9e8814cf4c69137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f17c49dba3704cedb5d8cfcbe6e330a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7bc07d0da2f24201b24719463c3a3b83",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_43a3ea5b4a034e829afa98d5deb38b56",
              "IPY_MODEL_25a17fc117ce4d2fbdc09407da8684bd"
            ]
          }
        },
        "7bc07d0da2f24201b24719463c3a3b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43a3ea5b4a034e829afa98d5deb38b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e52b851b40ef498f80cc24cb39d244b3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a64d5571c3e64611942c5d50720f4ee9"
          }
        },
        "25a17fc117ce4d2fbdc09407da8684bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c933b35da88445d8bdae31076766ff5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 52.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9d6c63fd4cf4ebc95ab720f0fb0f1d0"
          }
        },
        "e52b851b40ef498f80cc24cb39d244b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a64d5571c3e64611942c5d50720f4ee9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c933b35da88445d8bdae31076766ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9d6c63fd4cf4ebc95ab720f0fb0f1d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kh6kyDsZfSa"
      },
      "source": [
        "# Fachpraktikum AI University Stuttgart\n",
        "Author: Siyu Chen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s2KppPnaTOi"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UBzhGwElKT4",
        "outputId": "4cac47d5-3ccb-4768-b92f-7ab49cc47d15"
      },
      "source": [
        "!pip install lineflow\n",
        "!pip install transformers\n",
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lineflow\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/09/6e8842e1c8ace250d352cf59503e3939169d8a3abe0d17115d5916054930/lineflow-0.6.4.tar.gz\n",
            "Collecting arrayfiles\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/be/297c365c7f8304ffa949bb252eac9d67e5c708a3615c9d5b18a7613e9006/arrayfiles-0.0.1.tar.gz\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from lineflow) (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown->lineflow) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown->lineflow) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown->lineflow) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->lineflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->lineflow) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->lineflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->lineflow) (1.24.3)\n",
            "Building wheels for collected packages: lineflow, arrayfiles\n",
            "  Building wheel for lineflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lineflow: filename=lineflow-0.6.4-cp37-none-any.whl size=23201 sha256=1ed14724dc3bf79eb61759574269fa9eb4e53265e82d8800992b15f3d1bf80df\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/11/32/a6120f98d7d11ed8cf1b28b265a12a4b72842da341c13384c1\n",
            "  Building wheel for arrayfiles (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for arrayfiles: filename=arrayfiles-0.0.1-cp37-none-any.whl size=5434 sha256=c46047d52606ed64926da2bd8030c85096c9c93680037f9e8193b920ae8d89fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/43/9b/fb9049f9c3931d703182bd45418c3e8d67a6b6eded6325e16e\n",
            "Successfully built lineflow arrayfiles\n",
            "Installing collected packages: arrayfiles, lineflow\n",
            "Successfully installed arrayfiles-0.0.1 lineflow-0.6.4\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 19.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 52.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 52.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n",
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/0c/e2d52147ac12a77ee4e7fd7deb4b5f334cfb335af9133a0f2780c8bb9a2c/pytorch_lightning-1.2.10-py3-none-any.whl (841kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849kB 17.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (20.9)\n",
            "Collecting torchmetrics==0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/42/d984612cabf005a265aa99c8d4ab2958e37b753aafb12f31c81df38751c8/torchmetrics-0.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184kB 51.9MB/s \n",
            "\u001b[?25hCollecting PyYAML!=5.4.*,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 276kB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.8.1+cu101)\n",
            "Collecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 56.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.4.1)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 829kB 56.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3MB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.28.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.36.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.32.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (56.0.0)\n",
            "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (3.0.4)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296kB 51.2MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143kB 56.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (20.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Building wheels for collected packages: PyYAML, future\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=bacfdef441273a1f9dc583bf7836a5473b98574fc5d1972a903d5333f630557b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=ddbbe60c6cdd794408e42acf09902595b2efa156770cdc3a46bfb60dde66ce7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built PyYAML future\n",
            "Installing collected packages: torchmetrics, PyYAML, multidict, yarl, async-timeout, aiohttp, fsspec, future, pytorch-lightning\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.3.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.4.0 future-0.18.2 multidict-5.1.0 pytorch-lightning-1.2.10 torchmetrics-0.2.0 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnt_dJL-aGDH"
      },
      "source": [
        "## Import libraries which are needed for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmVZtxllk8w9"
      },
      "source": [
        "from typing import Dict\n",
        "from pathlib import Path\n",
        "import json\n",
        "from functools import partial\n",
        "from collections import OrderedDict\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import lineflow as lf\n",
        "from transformers import BertForMultipleChoice, BertTokenizer, AdamW\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykmf-YTlc7u6"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idQnyRDId1lj"
      },
      "source": [
        "### Useful function to process dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFOG_GiplB9h"
      },
      "source": [
        "MAX_LEN = 128\n",
        "NUM_LABELS = 4\n",
        "label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
        "\n",
        "\n",
        "def raw_samples_to_dataset(samples):\n",
        "    datas = []\n",
        "    for sample in samples:\n",
        "        for idx in range(len(sample[\"answers\"])):\n",
        "            _id = sample[\"id\"]\n",
        "            _article = sample[\"article\"]\n",
        "            _answer = sample[\"answers\"][idx]\n",
        "            _options = sample[\"options\"][idx]\n",
        "            _question = sample[\"questions\"][idx]\n",
        "\n",
        "            data = {\n",
        "                    \"id\": _id,\n",
        "                    \"article\": _article,\n",
        "                    \"answer\": _answer,\n",
        "                    \"options\": _options,\n",
        "                    \"question\": _question,\n",
        "                    }\n",
        "            datas.append(data)\n",
        "    return lf.Dataset(datas)\n",
        "\n",
        "\n",
        "def preprocess(tokenizer: BertTokenizer, x: Dict) -> Dict:\n",
        "\n",
        "    choices_features = []\n",
        "\n",
        "    option: str\n",
        "    for option in x[\"options\"]:\n",
        "        text_a = x[\"article\"]\n",
        "        if x[\"question\"].find(\"_\") != -1:\n",
        "            text_b = x[\"question\"].replace(\"_\", option)\n",
        "        else:\n",
        "            text_b = x[\"question\"] + \" \" + option\n",
        "\n",
        "        inputs = tokenizer.encode_plus(\n",
        "                text_a,\n",
        "                text_b,\n",
        "                add_special_tokens=True,\n",
        "                max_length=MAX_LEN\n",
        "                )\n",
        "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        pad_token_id = tokenizer.pad_token_id\n",
        "        padding_length = MAX_LEN - len(input_ids)\n",
        "        input_ids = input_ids + ([pad_token_id] * padding_length)\n",
        "        attention_mask = attention_mask + ([0] * padding_length)\n",
        "        token_type_ids = token_type_ids + ([pad_token_id] * padding_length)\n",
        "\n",
        "        assert len(input_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(input_ids), MAX_LEN)\n",
        "        assert len(attention_mask) == MAX_LEN, \"Error with input length {} vs {}\".format(len(attention_mask), MAX_LEN)\n",
        "        assert len(token_type_ids) == MAX_LEN, \"Error with input length {} vs {}\".format(len(token_type_ids), MAX_LEN)\n",
        "\n",
        "        choices_features.append({\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"token_type_ids\": token_type_ids,\n",
        "            })\n",
        "\n",
        "    labels = label_map.get(x[\"answer\"], -1)\n",
        "    label = torch.tensor(labels).long()\n",
        "\n",
        "    return {\n",
        "            \"id\": x[\"id\"],\n",
        "            \"label\": label,\n",
        "            \"input_ids\": torch.tensor([cf[\"input_ids\"] for cf in choices_features]),\n",
        "            \"attention_mask\": torch.tensor([cf[\"attention_mask\"] for cf in choices_features]),\n",
        "            \"token_type_ids\": torch.tensor([cf[\"token_type_ids\"] for cf in choices_features]),\n",
        "            }\n",
        "\n",
        "\n",
        "def get_dataloader(datadir: str, cachedir: str = \"./\"):\n",
        "    datadir = Path(datadir)\n",
        "    cachedir = Path(cachedir)\n",
        "    batch_size = 8\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "    preprocessor = partial(preprocess, tokenizer)\n",
        "\n",
        "    train_samples = []\n",
        "    for grade in (\"middle\", \"high\"):\n",
        "        for _path in (datadir / \"train\" / grade).iterdir():\n",
        "            train_samples.append(json.loads(_path.read_text()))\n",
        "    train = raw_samples_to_dataset(train_samples)\n",
        "    train_dataloader = DataLoader(\n",
        "            train.map(preprocessor).save(cachedir / \"train.cache\"),\n",
        "            sampler=RandomSampler(train),\n",
        "            batch_size=batch_size\n",
        "            )\n",
        "\n",
        "    val_samples = []\n",
        "    for grade in (\"middle\", \"high\"):\n",
        "        for _path in (datadir / \"dev\" / grade).iterdir():\n",
        "            val_samples.append(json.loads(_path.read_text()))\n",
        "    val = raw_samples_to_dataset(val_samples)\n",
        "    val_dataloader = DataLoader(\n",
        "            val.map(preprocessor).save(cachedir / \"val.cache\"),\n",
        "            sampler=SequentialSampler(val),\n",
        "            batch_size=batch_size\n",
        "            )\n",
        "\n",
        "    test_samples = []\n",
        "    for grade in (\"middle\", \"high\"):\n",
        "        for _path in (datadir / \"test\" / grade).iterdir():\n",
        "            test_samples.append(json.loads(_path.read_text()))\n",
        "    test = raw_samples_to_dataset(test_samples)\n",
        "    print(type(test.map(preprocessor)))\n",
        "    test_dataloader = DataLoader(\n",
        "            test.map(preprocessor).save(cachedir / \"test.cache\"),\n",
        "            sampler=SequentialSampler(test),\n",
        "            batch_size=batch_size\n",
        "            )\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsf2Mk0mdFZK"
      },
      "source": [
        "### Method 1: Download dataset and unzip dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fk9XAzZdUey"
      },
      "source": [
        "#### Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8ckit1Ol3qh",
        "outputId": "1dbbf98f-db09-418c-c8a8-2b2d22773a0e"
      },
      "source": [
        "!ls \n",
        "!wget http://www.cs.cmu.edu/~glai1/data/race/RACE.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "--2021-04-28 13:17:06--  http://www.cs.cmu.edu/~glai1/data/race/RACE.tar.gz\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25443609 (24M) [application/x-gzip]\n",
            "Saving to: â€˜RACE.tar.gzâ€™\n",
            "\n",
            "RACE.tar.gz         100%[===================>]  24.26M  3.05MB/s    in 11s     \n",
            "\n",
            "2021-04-28 13:17:18 (2.18 MB/s) - â€˜RACE.tar.gzâ€™ saved [25443609/25443609]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnE6ivhqdfWX"
      },
      "source": [
        "#### Unzip dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVA_Bvk5namn",
        "outputId": "5f6f225a-f87d-4543-e6e2-34fefc1ea805"
      },
      "source": [
        "!ls \n",
        "!tar -xf RACE.tar.gz && ls "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RACE.tar.gz  sample_data\n",
            "RACE  RACE.tar.gz  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D96OKgqUn9nT",
        "outputId": "c2bf948b-bc39-4e58-b71a-c665946e755b"
      },
      "source": [
        "!cd RACE && ls && pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev  test  train\n",
            "/content/RACE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZNZZJchd-vt"
      },
      "source": [
        "#### Call functions to handle raw dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8o9Dkay1AvG"
      },
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = get_dataloader('/content/RACE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR7F_VCq0x_V",
        "outputId": "9d26aea6-3f40-469a-92a4-39385cfdf74e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RACE  RACE.tar.gz  sample_data\ttest.cache  train.cache  val.cache\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHl9f2XxeIRS"
      },
      "source": [
        "### Method 2: Load `DataLoader` from the path which e.g. `train.cache`, `val.cache` and `test.cache`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNjkAw8aewFM"
      },
      "source": [
        "#### Mounting Google Drive locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt4gKpGVPh32",
        "outputId": "0f76b99d-a828-47f4-c839-1dcbb374ba41"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-bTsWFbe_6E"
      },
      "source": [
        "#### Check whether `train.cache`, `val.cache` and `test.cache` are saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sL9BtUePOMB",
        "outputId": "bffd3b06-c839-4ea9-d4ae-67f4e67970af"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  RACE  RACE.tar.gz  sample_data  test.cache  train.cache\tval.cache\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fn6m5gRfR1j"
      },
      "source": [
        "#### Copy `train.cache`, `val.cache` and `test.cache` into Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHEov6FXPu5V",
        "outputId": "f3bdca6b-5179-4c46-a0fd-812d4dbe77ff"
      },
      "source": [
        "!ls\n",
        "!cp train.cache /content/drive/My\\ Drive/Fachpraktikum/\n",
        "!cp val.cache /content/drive/My\\ Drive/Fachpraktikum/\n",
        "!cp test.cache /content/drive/My\\ Drive/Fachpraktikum/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  RACE  RACE.tar.gz  sample_data  test.cache  train.cache\tval.cache\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch7aimPMfrPI"
      },
      "source": [
        "#### Check whether `train.cache`, `val.cache` and `test.cache` are in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlhYgla_Ql5o",
        "outputId": "1c1f40b0-56de-4abb-d125-5e54828a7bd4"
      },
      "source": [
        "!ls /content/drive/My\\ Drive/Fachpraktikum/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.cache  train.cache  val.cache\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdlBZ2s1f4b0"
      },
      "source": [
        "#### Load from Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqZXsA99X1GR",
        "outputId": "f0d765e5-968f-41ac-c112-77707b06ab54"
      },
      "source": [
        "train_dataloader_drive, val_dataloader_drive, test_dataloader_drive = get_dataloader('/content/RACE', '/content/drive/My Drive/Fachpraktikum/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data from /content/drive/My Drive/Fachpraktikum/train.cache...\n",
            "Loading data from /content/drive/My Drive/Fachpraktikum/val.cache...\n",
            "<class 'lineflow.core.MapDataset'>\n",
            "Loading data from /content/drive/My Drive/Fachpraktikum/test.cache...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyWCjsYEidWm"
      },
      "source": [
        "## Play around with `DataLoader`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX29d_V2iwwG"
      },
      "source": [
        "### Get a batch of dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRTt91ytx0Wg"
      },
      "source": [
        "sample = next(iter(test_dataloader_drive))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViMgojHxi2DG"
      },
      "source": [
        "### Print some information of dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GnTDxdaymAl",
        "outputId": "2983dc67-d9ed-4c35-b775-7221d2beee88"
      },
      "source": [
        "# type of sample\n",
        "print(type(sample))\n",
        "# keys of sample\n",
        "print(sample.keys())\n",
        "# ids of sample\n",
        "print(sample['id'])\n",
        "# label of sample\n",
        "print(sample['label'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['id', 'label', 'input_ids', 'attention_mask', 'token_type_ids'])\n",
            "['middle6853.txt', 'middle6853.txt', 'middle6853.txt', 'middle5870.txt', 'middle5870.txt', 'middle5870.txt', 'middle7476.txt', 'middle7476.txt']\n",
            "tensor([1, 3, 1, 0, 1, 2, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSpZpJYY0iZG",
        "outputId": "4a681755-ac5e-4925-a797-eba9ab334c83"
      },
      "source": [
        "# tokenised context and question\n",
        "print(sample['input_ids'][0].size())\n",
        "print(sample['input_ids'][0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 128])\n",
            "tensor([ 101, 2023, 2095, 1010, 1000, 3748, 2859, 1000, 2003, 3297, 1010, 2009,\n",
            "        3065, 2149, 1996, 3376, 5019, 1012, 2021, 1999, 2755, 1010, 1996, 4044,\n",
            "        2105, 2149, 2003, 2893, 4788, 1998, 4788, 1012, 1999, 2070, 3182, 1010,\n",
            "        2057, 2064, 1005, 1056, 2156, 3869, 5742, 1999, 1996, 2314, 2030, 3628,\n",
            "        2006, 1996, 4020, 1012, 2116, 4176, 2024, 5307, 1996, 5473, 1997, 2542,\n",
            "        1012, 2012, 1996, 2168, 2051, 1010, 2158, 2003, 4288, 4176, 2074, 2005,\n",
            "        2893, 2037, 3096, 1998, 6240, 1012, 1999, 2256, 2406, 1010, 1996, 2193,\n",
            "        1997, 3748, 4176, 2003, 3352, 3760, 1998, 3760, 1012, 2070, 1997, 2068,\n",
            "        2024, 2130, 5996, 2041, 1012, 2009, 1005, 1055, 2051, 2000, 4047, 2256,\n",
            "        4044, 1012, 2021, 2054, 2064, 2057, 2079, 1029,  102, 2054, 2055, 2256,\n",
            "        4044, 2105, 2149, 1999, 2755, 1029, 2488,  102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DtiQ-Q4jXho"
      },
      "source": [
        "### Decode tokenised context and question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRH6g1D706WW"
      },
      "source": [
        "de_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "khPEjv_Z1AEk",
        "outputId": "0d764995-f1bd-497d-c4d0-1df02b040dd3"
      },
      "source": [
        "de_tokenizer.decode(sample['input_ids'][0][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] this year, \" wild china \" is famous, it shows us the beautiful scenes. but in fact, the environment around us is getting worse and worse. in some places, we can\\'t see fish swimming in the river or trees on the mountains. many animals are facing the danger of living. at the same time, man is killing animals just for getting their skin and meat. in our country, the number of wild animals is becoming smaller and smaller. some of them are even dying out. it\\'s time to protect our environment. but what can we do? [SEP] what about our environment around us in fact? worse [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd956g7TjvGu"
      },
      "source": [
        "## Model for training and evaluating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v3ZVu_Uj39l"
      },
      "source": [
        "### Load a pre-trained bert model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "094ca1acabff4fa9bebf66d30b892b04",
            "757c4f1b645a47f287cef92eeb2dbf0e",
            "6b07a54eaacf4efaaf79144c5b7c8bc8",
            "696a17218952435db2c10047a277a28d",
            "49813d5246b143ca88937af6708cf02f",
            "860260ca4af043199432297156fac085",
            "ebd0a509636546d79e3ac7cf4f87c6a0",
            "b2204240fd234160a9e8814cf4c69137",
            "f17c49dba3704cedb5d8cfcbe6e330a4",
            "7bc07d0da2f24201b24719463c3a3b83",
            "43a3ea5b4a034e829afa98d5deb38b56",
            "25a17fc117ce4d2fbdc09407da8684bd",
            "e52b851b40ef498f80cc24cb39d244b3",
            "a64d5571c3e64611942c5d50720f4ee9",
            "7c933b35da88445d8bdae31076766ff5",
            "a9d6c63fd4cf4ebc95ab720f0fb0f1d0"
          ]
        },
        "id": "95S-tcq7Ih-u",
        "outputId": "880a27d2-4249-47a0-e9f7-67eacc6892a2"
      },
      "source": [
        "model = BertForMultipleChoice.from_pretrained('bert-base-uncased')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "094ca1acabff4fa9bebf66d30b892b04",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f17c49dba3704cedb5d8cfcbe6e330a4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0awQuZoQkJSd"
      },
      "source": [
        "### Send model to cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lox59M1Qxqp",
        "outputId": "381680b6-48f8-43d7-bbdc-d70b01d0d843"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMultipleChoice(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1leugqjqKeW0"
      },
      "source": [
        "# for data_batch in test_dataloader:\n",
        "#     outputs = model(data_batch['input_ids'])\n",
        "#     print(outputs.logits)\n",
        "outputs = model(sample['input_ids'].cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFJskbcpRwvi",
        "outputId": "6c623ee8-1410-417a-db71-9115107ea876"
      },
      "source": [
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultipleChoiceModelOutput(loss=None, logits=tensor([[-0.0644, -0.0354, -0.0719, -0.0486],\n",
            "        [-0.0656, -0.0640, -0.0629, -0.0680],\n",
            "        [-0.0952, -0.0897, -0.0616, -0.1100],\n",
            "        [-0.1236, -0.1179, -0.1265, -0.1479],\n",
            "        [-0.1058, -0.0980, -0.1378, -0.0976],\n",
            "        [-0.1078, -0.0733, -0.1203, -0.1145],\n",
            "        [-0.1252, -0.0966, -0.0598, -0.0049],\n",
            "        [-0.1945, -0.2054, -0.1876, -0.1874]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>), hidden_states=None, attentions=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxocAef3LudV"
      },
      "source": [
        "soft_max = torch.nn.Softmax(dim=1)\n",
        "after_softmax = soft_max(outputs.logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkd-1eNBMM8n",
        "outputId": "3df290e8-7e00-4e16-ceec-94c6f263d711"
      },
      "source": [
        "torch.argmax(after_softmax, dim=1).cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 2, 1, 3, 1, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp-htmx2NdqX"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7VlcpReSmAP",
        "outputId": "df82d1cf-476b-4161-b85d-12fdd266b2d2"
      },
      "source": [
        "a = torch.tensor([]).cuda()\n",
        "b = torch.tensor([1]).cuda()\n",
        "torch.cat((a, b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zruqrCbUA8J"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkrIGScUU2Xo"
      },
      "source": [
        "test_dataloader_large = torch.utils.data.DataLoader(test_dataloader_drive.dataset, batch_size=16, shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsig3WcMMzUW"
      },
      "source": [
        "soft_max = torch.nn.Softmax(dim=1)\n",
        "pred = torch.tensor([]).cuda()\n",
        "for data_batch in test_dataloader:\n",
        "    outputs = model(data_batch['input_ids'].cuda())\n",
        "    after_softmax = soft_max(outputs.logits)\n",
        "    pred = torch.cat((pred,torch.argmax(after_softmax, dim=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s06iNYi5aWVr",
        "outputId": "df2fe9e1-e1ef-40d1-f9f1-71cb47d94145"
      },
      "source": [
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 3., 3.,  ..., 2., 1., 0.], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmX-gtgQacG5"
      },
      "source": [
        "pred_np = pred.cpu().numpy().astype(np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWBb4qkeat0C",
        "outputId": "1b10ecad-d38c-4dd9-9d8d-5bf8fc571f6d"
      },
      "source": [
        "print(pred_np)\n",
        "print(len(pred_np))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 3 3 ... 2 1 0]\n",
            "4934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSAQzEl0a5zi"
      },
      "source": [
        "labels = torch.tensor([])\n",
        "for data_batch in test_dataloader:\n",
        "    labels = torch.cat((labels, data_batch['label']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QefKiJA1bX3d",
        "outputId": "52eb7873-8fad-44c2-c1db-db0c49419291"
      },
      "source": [
        "labels_np = labels.cpu().numpy().astype(np.int32)\n",
        "print(type(labels_np))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdQzTH3lcbNN",
        "outputId": "3474f3b2-ea0b-471f-a4f1-ad27e815290a"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(labels_np, pred_np)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[290, 249, 265, 259],\n",
              "       [320, 353, 307, 343],\n",
              "       [334, 298, 329, 363],\n",
              "       [292, 295, 296, 341]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko_fKE4D2sy1"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(3):\n",
        "    for batch in train_dataloader_drive:\n",
        "        optim.zero_grad()\n",
        "        outputs = model(data_batch['input_ids'].cuda(), )\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AL2uFrV2aRP"
      },
      "source": [
        "class Model(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, args):\n",
        "        super(Model, self).__init__()\n",
        "        model = BertForMultipleChoice.from_pretrained(\"bert-base-uncased\", num_labels=NUM_LABELS)\n",
        "        self.model = model\n",
        "\n",
        "        train_dataloader, val_dataloader, test_dataloader = get_dataloader(args.data_dir)\n",
        "        self._train_dataloader = train_dataloader\n",
        "        self._val_dataloader = val_dataloader\n",
        "        self._test_dataloader = test_dataloader\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        no_decay = ['bias', 'LayerNorm.weight']\n",
        "        weight_decay = 0.0\n",
        "        adam_epsilon = 1e-8\n",
        "\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                'weight_decay': weight_decay\n",
        "                },\n",
        "            {\n",
        "                'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                'weight_decay': 0.0,\n",
        "                }\n",
        "            ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5, eps=adam_epsilon)\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        labels = batch[\"label\"]\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        token_type_ids = batch[\"token_type_ids\"]\n",
        "\n",
        "        loss, _ = self.model(\n",
        "                input_ids,\n",
        "                token_type_ids=token_type_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "                )\n",
        "\n",
        "        tqdm_dict = {\"train_loss\": loss}\n",
        "        output = OrderedDict({\n",
        "            \"loss\": loss,\n",
        "            \"progress_bar\": tqdm_dict,\n",
        "            \"log\": tqdm_dict,\n",
        "            })\n",
        "\n",
        "        return output\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        labels = batch[\"label\"]\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        token_type_ids = batch[\"token_type_ids\"]\n",
        "\n",
        "        loss, logits = self.model(\n",
        "                input_ids,\n",
        "                token_type_ids=token_type_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "                )\n",
        "        labels_hat = torch.argmax(logits, dim=1)\n",
        "\n",
        "        correct_count = torch.sum(labels == labels_hat)\n",
        "\n",
        "        if self.on_gpu:\n",
        "            correct_count = correct_count.cuda(loss.device.index)\n",
        "\n",
        "        output = OrderedDict({\n",
        "                \"val_loss\": loss,\n",
        "                \"correct_count\": correct_count,\n",
        "                \"batch_size\": len(labels)\n",
        "                })\n",
        "\n",
        "        return output\n",
        "\n",
        "    def validation_end(self, outputs):\n",
        "        val_acc = sum([out[\"correct_count\"] for out in outputs]).float() / sum(out[\"batch_size\"] for out in outputs)\n",
        "        val_loss = sum([out[\"val_loss\"] for out in outputs]) / len(outputs)\n",
        "        tqdm_dict = {\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_acc\": val_acc,\n",
        "                }\n",
        "        return {\"progress_bar\": tqdm_dict, \"log\": tqdm_dict, \"val_loss\": val_loss}\n",
        "\n",
        "    @pl.data_loader\n",
        "    def train_dataloader(self):\n",
        "        return self._train_dataloader\n",
        "\n",
        "    @pl.data_loader\n",
        "    def val_dataloader(self):\n",
        "        return self._val_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}